{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ulhVYI86xhZ"
   },
   "source": [
    "# Assignment 3\n",
    "\n",
    "**Submission deadlines:**\n",
    "\n",
    "  - Tuesday groups: 22.04.2025\n",
    "  - Friday groups: 18.04.2025\n",
    "\n",
    "**Points:** Aim to get 10 points + 4 extra\n",
    "\n",
    "## Submission instructions\n",
    "The class is held on-site in lab rooms. Please prepare you notebook on your computer or anywhere in the cloud (try using DeepNote or Google Colab).\n",
    "\n",
    "Make sure you know all the questions and answers, and that the notebook contains results; before presentation do `Runtime -> Restart and run all`\n",
    "\n",
    "![Alt text](data:image/png;base64,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)\n",
    "\n",
    "We provide starter code, however you are not required to use it as long as you properly solve the tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pq455pMGbe2"
   },
   "source": [
    "# Classify the Oxford Flowers dataset (Weight & Biases) [6p]\n",
    "\n",
    "In this task, you will train a convolutional neural network to classify images of flowers from the [Oxford Flowers 102 dataset](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/). The dataset consists of 102 flower categories, and each class has between 40 and 258 images. The images have large scale, pose, and light variations. In addition, there are categories that have large variations within the category and several very similar categories.\n",
    "\n",
    "    \n",
    "The dataset is available in `torchvision.datasets.Flowers102` class; see [Flowers102.html](https://pytorch.org/vision/main/generated/torchvision.datasets.Flowers102.html). You can use the following code to load the dataset:\n",
    "\n",
    "```python\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "dataset = torchvision.datasets.Flowers102(root='./data', download=True, transform=transforms.ToTensor())\n",
    "```\n",
    "\n",
    "**Hint**: The default split of the dataset is 1020, 1020 and 6149 images for training, validation and test sets respectively.\n",
    "If you can handle the bigger training dataset, you can experiment by taking up to 80% of the test set for training.\n",
    "\n",
    "\n",
    "In this task you should run several experiments to classify the images.\n",
    "In order to track the experiments, you can use the `Weight & Biases` library; see the [documentation](https://docs.wandb.ai/quickstart) for more details.\n",
    "\n",
    "Implement your code as a single Python script or a Jupyter notebook. Remember to log the experiment configuration, hyperparameters, and results (e.g., training loss, validation loss, accuracy and test loss, accuracy).\n",
    "For logging, you can use the `wandb.log` function to log the metrics and hyperparameters. You can also log the model architecture, training curves, and other relevant information.\n",
    "\n",
    "* 1. **[1p]**:\n",
    "    * Your task is to implement a convolutional neural network from scratch using PyTorch.\n",
    "    * Your CNN should consist of convolutional layers (Conv2D), pooling layers (MaxPooling2D), activation layers (e.g., ReLU), and fully connected layers (if needed).\n",
    "    \n",
    "* 2. **[2p]**:\n",
    "    * Train your CNN on different training set sized (10%, 20%, 50%, 80%, 100%) and evaluate the performance on the validation set and test set.\n",
    "        * Report the accuracy and loss on the validation set and test set for each training set size.\n",
    "    * Train your CNN on the full training set plus 20%, 50% and 80% of the test set and evaluate the performance on the validation set and the remaining test set.\n",
    "        * Report the accuracy and loss on the validation set and remaining test set for each training set size.\n",
    "    * Compare the performance of your CNN on the different training set sizes and analyze the results.\n",
    "\n",
    "* 3. **[1p]**:\n",
    "    * Implement a baseline AlexNet model using PyTorch.\n",
    "    * Training AlexNet may take a long time, so try to use GPU acceleration if available.\n",
    "\n",
    "* 4. **[1p]**:\n",
    "    * Input normalization: experiment with different input normalization techniques (e.g., mean subtraction, standardization) and analyze their impact on the model's performance.\n",
    "\n",
    "* 5. **[2p]**:\n",
    "    * Experiment with different hyperparameters such as learning rate, batch size, number of epochs, and optimizer choice (e.g., SGD, Adam).\n",
    "\n",
    "* 6. **[2p]**:\n",
    "    * Modify your CNN architecture to include batch normalization and dropout layers.\n",
    "    * Experiment with different dropout rates and analyze their impact on the model's performance.\n",
    "\n",
    "* 7. **[1p]**:\n",
    "    * Implement data augmentation techniques such as random rotations, shifts, flips, and zooms on the training dataset.\n",
    "    * Train your CNN with augmented data and compare the performance with the baseline model trained on the original data.\n",
    "\n",
    "* 8. ***[2p extra points]***:\n",
    "    * Implement residual connections in your CNN architecture; see the [ResNet paper](https://arxiv.org/abs/1512.03385) for more details.\n",
    "    * Implement inception modules in your CNN architecture; see the [GoogLeNet paper](https://arxiv.org/abs/1409.4842) for more details.\n",
    "                \n",
    "\n",
    "Analyze the results obtained from different experiments.\n",
    "Discuss the effects of varying training set size, hyperparameters, batch normalization, dropout, and data augmentation on the CNN's performance.\n",
    "Provide insights into how these factors influence model training, convergence, and generalization.\n",
    "\n",
    "Use the `Weight & Biases` reports to present your findings in a comprehensive report or presentation; see the [documentation](https://docs.wandb.ai/quickstart) for more details.\n",
    "\n",
    "**[2p extra]**: present your findings (for each task) in a report format in Weight & Biases.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQaf_QBHGbe2"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
