{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7da195",
   "metadata": {},
   "source": [
    "# Q&A\n",
    "* how to determine data split between train, validation and test sets? Since we cannot use the test set for any observation, is it even possible?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98eeaba",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0358b4a",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c858342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86fbd696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: torch in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.0+cu126)\n",
      "Requirement already satisfied: torchvision in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: wandb in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.19.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\patry\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\patry\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\patry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib torch torchvision numpy pandas scikit-learn wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f70dc75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b65df0e",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6df5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {_device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e741ab63",
   "metadata": {},
   "source": [
    "## Import data\n",
    "**About data:** The dataset consists of 102 flower categories, and each class has between 40 and 258 images. The images have large scale, pose, and light variations. In addition, there are categories that have large variations within the category and several very similar categories.  \n",
    "The default split of the dataset is 1020, 1020 and 6149 images for training, validation and test sets respectively.\n",
    "If you can handle the bigger training dataset, you can experiment by taking up to 80% of the test set for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312c2351",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemDataLoader(object):\n",
    "    \"\"\"\n",
    "    A data loader that keeps all data in CPU or GPU memory.\n",
    "    \"\"\"\n",
    "\n",
    "    __initialized = False\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        sampler=None,\n",
    "        batch_sampler=None,\n",
    "        drop_last=False,\n",
    "    ):\n",
    "        \"\"\"A torch dataloader that fetches data from memory.\"\"\"\n",
    "        batches = []\n",
    "        for i in tqdm(range(len(dataset))):\n",
    "            batch = [torch.tensor(t) for t in dataset[i]]\n",
    "            batches.append(batch)\n",
    "        tensors = [torch.stack(ts) for ts in zip(*batches)]\n",
    "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "\n",
    "        if batch_sampler is not None:\n",
    "            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
    "                raise ValueError(\n",
    "                    \"batch_sampler option is mutually exclusive \"\n",
    "                    \"with batch_size, shuffle, sampler, and \"\n",
    "                    \"drop_last\"\n",
    "                )\n",
    "            self.batch_size = None\n",
    "            self.drop_last = None\n",
    "\n",
    "        if sampler is not None and shuffle:\n",
    "            raise ValueError(\"sampler option is mutually exclusive with \" \"shuffle\")\n",
    "\n",
    "        if batch_sampler is None:\n",
    "            if sampler is None:\n",
    "                if shuffle:\n",
    "                    sampler = torch.utils.data.RandomSampler(dataset)\n",
    "                else:\n",
    "                    sampler = torch.utils.data.SequentialSampler(dataset)\n",
    "            batch_sampler = torch.utils.data.BatchSampler(\n",
    "                sampler, batch_size, drop_last\n",
    "            )\n",
    "\n",
    "        self.sampler = sampler\n",
    "        self.batch_sampler = batch_sampler\n",
    "        self.__initialized = True\n",
    "\n",
    "    def __setattr__(self, attr, val):\n",
    "        if self.__initialized and attr in (\"batch_size\", \"sampler\", \"drop_last\"):\n",
    "            raise ValueError(\n",
    "                \"{} attribute should not be set after {} is \"\n",
    "                \"initialized\".format(attr, self.__class__.__name__)\n",
    "            )\n",
    "\n",
    "        super(InMemDataLoader, self).__setattr__(attr, val)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch_indices in self.batch_sampler:\n",
    "            yield self.dataset[batch_indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)\n",
    "\n",
    "    def to(self, device):\n",
    "        self.dataset.tensors = tuple(t.to(device) for t in self.dataset.tensors)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c46a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flowers(batch_size=64, test_train_valid_percent=(0.1, 0.8, 0.1), transform=None, Loader=torch.utils.data.DataLoader):\n",
    "    \"\"\"\n",
    "    Load the flowers dataset with the given batch size and transformation.\n",
    "    The dataset is split into train, validation, and test sets according to the specified percentages.\n",
    "    The data is loaded using the specified loader class.\n",
    "    \"\"\"\n",
    "\n",
    "    if transform is None:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "    test_percent, train_percent, valid_percent = test_train_valid_percent\n",
    "\n",
    "    test = torchvision.datasets.Flowers102(\n",
    "        root='./data', split='test', download=True, transform=transform\n",
    "    )\n",
    "    test = torch.utils.data.Subset(test, range(int(len(test) * test_percent)))\n",
    "\n",
    "    train = torchvision.datasets.Flowers102(\n",
    "        root='./data', split='train', download=True, transform=transform\n",
    "    )\n",
    "    train = torch.utils.data.Subset(train, range(int(len(train) * train_percent)))\n",
    "\n",
    "    valid = torchvision.datasets.Flowers102(\n",
    "        root='./data', split='val', download=True, transform=transform\n",
    "    )\n",
    "    valid = torch.utils.data.Subset(valid, range(int(len(valid) * valid_percent)))\n",
    "\n",
    "    data_loaders = {\n",
    "        'train': Loader(train, batch_size=batch_size, shuffle=True),\n",
    "        'valid': Loader(valid, batch_size=batch_size, shuffle=False),\n",
    "        'test': Loader(test, batch_size=batch_size, shuffle=False),\n",
    "    }\n",
    "\n",
    "    return data_loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "511b4223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1020 [00:00<?, ?it/s]C:\\Users\\patry\\AppData\\Local\\Temp\\ipykernel_10748\\2199848925.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = [torch.tensor(t) for t in dataset[i]]\n",
      "100%|██████████| 1020/1020 [00:10<00:00, 100.07it/s]\n",
      "100%|██████████| 1020/1020 [00:09<00:00, 104.65it/s]\n",
      "100%|██████████| 6149/6149 [00:59<00:00, 103.79it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "data_loaders = load_flowers(batch_size, (1, 1, 1), transform=None, Loader=InMemDataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443248f7",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedf7b0e",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d5823a",
   "metadata": {},
   "source": [
    "### Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91326d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cb926eb",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c94c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Model1, self).__init__()\n",
    "        self.layers = nn.Sequential(*args, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf022b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    loss_fn = nn.CrossEntropyLoss(\n",
    "        reduction='sum',\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(_device), labels.to(_device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss += loss_fn(outputs, labels).item()\n",
    "            pred = outputs.argmax(\n",
    "                dim=1, keepdim=True\n",
    "            )\n",
    "            correct += (\n",
    "                pred.eq(labels.view_as(pred)).sum().item()\n",
    "            )\n",
    "    \n",
    "    loss /= len(data_loader.dataset)\n",
    "    accuracy = correct / len(data_loader.dataset)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35647d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, loss_fn):\n",
    "    for batch_idx, (inputs, labels) in enumerate(data_loaders['train']):\n",
    "        inputs, labels = inputs.to(_device), labels.to(_device)\n",
    "\n",
    "        optimizer.zero_grad()   # Zero gradients\n",
    "        logits = model(inputs)   # Forward pass\n",
    "        loss = loss_fn(logits, labels)  # Compute loss\n",
    "        loss.backward() # Backward pass\n",
    "        optimizer.step()    # Update weights\n",
    "        \n",
    "        wandb.log({\n",
    "            \"loss\": loss.item(),\n",
    "            \"batch_idx\": batch_idx,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e21bb9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(model):\n",
    "    \"\"\"\n",
    "    Initialize weights of the model using Kaiming uniform distribution.\n",
    "    \"\"\"\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            nn.init.kaiming_uniform_(layer.weight, nonlinearity='relu')\n",
    "            if layer.bias is not None:\n",
    "                nn.init.zeros_(layer.bias)\n",
    "        elif isinstance(layer, nn.Linear):\n",
    "            nn.init.xavier_uniform_(layer.weight, gain=1.0)\n",
    "            if layer.bias is not None:\n",
    "                nn.init.zeros_(layer.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f486fbb5",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1 of model - too simple\n",
    "model_type = \"v1\"\n",
    "\n",
    "model = Model1(\n",
    "    nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(p=0.25),\n",
    "\n",
    "    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(p=0.25),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128 * 56 * 56, 512),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(512, 102),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "585d2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2\n",
    "model_type = \"v2\"\n",
    "\n",
    "model = Model1(\n",
    "    nn.Conv2d(3, 128, kernel_size=11, stride=4, padding=2),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=5, stride=2),\n",
    "    nn.Dropout(p=0.25),\n",
    "\n",
    "    nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(p=0.25),\n",
    "\n",
    "    nn.Conv2d(256, 256, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(p=0.25),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(6400, 512),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(512, 102),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d22e04ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked 3x3 convs\n",
    "model_type = \"v3_stack3x3\"\n",
    "\n",
    "model = Model1(\n",
    "    nn.Conv2d(3, 64, kernel_size=5, stride=3, padding=2),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Conv2d(64, 128, kernel_size=3),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=3, stride=3),\n",
    "    nn.Dropout(p=0.25),\n",
    "\n",
    "    nn.Conv2d(128, 256, kernel_size=3, stride=2),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Conv2d(256, 256, kernel_size=3),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=3, stride=3),\n",
    "    nn.Dropout(p=0.25),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2304, 1024),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(512, 102),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e479d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 3 = alexnet\n",
    "model_type = \"alexnet\"\n",
    "\n",
    "model = Model1(\n",
    "    nn.Conv2d(3, 96, kernel_size=11, stride=4),\n",
    "    nn.BatchNorm2d(96),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Dropout(p=0.25),\n",
    "\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Dropout(p=0.25),\n",
    "\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(384),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.25),\n",
    "\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(384),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.25),\n",
    "\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Dropout(p=0.25),\n",
    "\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(6400, 4096),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(4096, 102),\n",
    "    # nn.Softmax(dim=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab90a9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Task1_1744585728</strong> at: <a href='https://wandb.ai/fejowo5522-/NN_list3_OxFlow/runs/wdgov1zh' target=\"_blank\">https://wandb.ai/fejowo5522-/NN_list3_OxFlow/runs/wdgov1zh</a><br> View project at: <a href='https://wandb.ai/fejowo5522-/NN_list3_OxFlow' target=\"_blank\">https://wandb.ai/fejowo5522-/NN_list3_OxFlow</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250414_010846-wdgov1zh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\SharedData\\Documents\\Programming\\UWr\\Sem6\\NN\\List3\\wandb\\run-20250414_010901-qk6poxch</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fejowo5522-/NN_list3_OxFlow/runs/qk6poxch' target=\"_blank\">dauntless-moon-61</a></strong> to <a href='https://wandb.ai/fejowo5522-/NN_list3_OxFlow' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fejowo5522-/NN_list3_OxFlow' target=\"_blank\">https://wandb.ai/fejowo5522-/NN_list3_OxFlow</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fejowo5522-/NN_list3_OxFlow/runs/qk6poxch' target=\"_blank\">https://wandb.ai/fejowo5522-/NN_list3_OxFlow/runs/qk6poxch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     45\u001b[39m model.train()\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs), desc=\u001b[33m\"\u001b[39m\u001b[33mTraining\u001b[39m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m loader, split \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m     50\u001b[39m         (data_loaders[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     51\u001b[39m         (data_loaders[\u001b[33m'\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     52\u001b[39m     ]:\n\u001b[32m     53\u001b[39m         loss, accuracy = evaluate(model, loader)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(model, optimizer, loss_fn)\u001b[39m\n\u001b[32m      8\u001b[39m loss.backward() \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m      9\u001b[39m optimizer.step()    \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[32m     11\u001b[39m wandb.log({\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbatch_idx\u001b[39m\u001b[33m\"\u001b[39m: batch_idx,\n\u001b[32m     14\u001b[39m })\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model.to(_device)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "learning_rate = 0.0001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005\n",
    "betas = (0.9, 0.999)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    betas=betas,\n",
    "    weight_decay=weight_decay,\n",
    ")\n",
    "# optimizer = torch.optim.SGD(\n",
    "#     model.parameters(),\n",
    "#     lr=learning_rate,\n",
    "#     momentum=momentum,\n",
    "#     weight_decay=weight_decay,\n",
    "# )\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "init_weights(model)\n",
    "\n",
    "run = wandb.init(\n",
    "    entity = \"fejowo5522-\",\n",
    "    project= \"NN_list3_OxFlow\",\n",
    "    config = {\n",
    "        \"task\": 1,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"optimizer\": \"SGD\",\n",
    "        \"learning_rate\": learning_rate,\n",
    "        # \"momentum\": momentum,\n",
    "        \"betas\": betas,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"loss_fn\": \"cross_entropy\",\n",
    "        \"model\": model_type,\n",
    "    }\n",
    ")\n",
    "run.name = \"Task1_\" + str(int(time.time()))\n",
    "\n",
    "model.train()\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "    train_step(model, optimizer, loss_fn)\n",
    "\n",
    "    for loader, split in [\n",
    "        (data_loaders['train'], 'train'),\n",
    "        (data_loaders['valid'], 'valid'),\n",
    "    ]:\n",
    "        loss, accuracy = evaluate(model, loader)\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            f\"{split}_loss\": loss,\n",
    "            f\"{split}_accuracy\": accuracy,\n",
    "        })\n",
    "\n",
    "loss, accuracy = evaluate(model, data_loaders['test'])\n",
    "wandb.log({\n",
    "    \"test_loss\": loss,\n",
    "    \"test_accuracy\": accuracy,\n",
    "})\n",
    "print(\n",
    "    \"Test set: Average loss: {:8.6f}, Accuracy: ({:4.1f}%)\".format(\n",
    "        loss,\n",
    "        100.0 * accuracy,\n",
    "    )\n",
    ")\n",
    "\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
