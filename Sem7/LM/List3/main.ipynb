{"cells":[{"cell_type":"markdown","id":"065b4efd","metadata":{"id":"065b4efd"},"source":["# Zadanie 1. (4+Xp)\n","\n","Zajmiemy się osadzeniami słów (zarówno kontekstowymi, jak i bezkontekstowymi). Uwaga: teksty, które będziemy osadzać zawsze składają się z jednego słowa (ale niekoniecznie z jednego tokenu).\n","\n","**a)** Zaproponuj jakiś sposób wykorzystania bezkontekstowych osadzeń tokenów (wyznaczanych przez transformer) do wyznaczenia osadzeń słów. Możesz skorzystać z programu z wykładu 7 (`embedding.ipynb`). Sprawdź, jaką jakość (mierzoną testem ABX) mają te osadzenia. Do zaliczenia zadania wymagane jest 0.6.\n","\n","**b)** Wykorzystaj kontekstowe osadzenia tokenów z BERT-a do wyznaczenia osadzeń dla słów. Ponownie wykonaj testy ABX.\n","\n","**c)** Spróbuj połączyć te dwa podejścia w jakikolwiek sposób. Jakość twojego rozwiązania przekłada się na punkty bonusowe zgodnie z wzorem: `(score − 0.6) × 6`\n","\n","**Procedura ewaluacji** (być może zostanie uproszczona): osadzenia zapisz w pliku tekstowym `word_embedings_file.txt`, w którym każdy wiersz wygląda tak:\n","\n","```\n","[słowo] float_1 float_2 ... float_D\n","```\n","\n","Osadzenia są oceniane za pomocą skryptu `word_emb_evaluation.py`."]},{"cell_type":"code","execution_count":220,"id":"edce7538","metadata":{"executionInfo":{"elapsed":42,"status":"ok","timestamp":1767361692967,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"},"user_tz":-60},"id":"edce7538"},"outputs":[],"source":["clusters_txt = '''\n","piśmiennicze: pisak flamaster ołówek długopis pióro\n","małe_ssaki: mysz szczur chomik łasica kuna bóbr\n","okręty: niszczyciel lotniskowiec trałowiec krążownik pancernik fregata korweta\n","lekarze: lekarz pediatra ginekolog kardiolog internista geriatra\n","zupy: rosół żurek barszcz\n","uczucia: miłość przyjaźń nienawiść gniew smutek radość strach\n","działy_matematyki: algebra analiza topologia logika geometria\n","budynki_sakralne: kościół bazylika kaplica katedra świątynia synagoga zbór\n","stopień_wojskowy: chorąży podporucznik porucznik kapitan major pułkownik generał podpułkownik\n","grzyby_jadalne: pieczarka borowik gąska kurka boczniak kania\n","prądy_filozoficzne: empiryzm stoicyzm racjonalizm egzystencjalizm marksizm romantyzm\n","religie: chrześcijaństwo buddyzm islam prawosławie protestantyzm kalwinizm luteranizm judaizm\n","dzieła_muzyczne: sonata synfonia koncert preludium fuga suita\n","cyfry: jedynka dwójka trójka czwórka piątka szóstka siódemka ósemka dziewiątka\n","owady: ważka biedronka żuk mrówka mucha osa pszczoła chrząszcz\n","broń_biała: miecz topór sztylet nóż siekiera\n","broń_palna: karabin pistolet rewolwer fuzja strzelba\n","komputery: komputer laptop kalkulator notebook\n","kolory: biel żółć czerwień błękit zieleń brąz czerń\n","duchowny: wikary biskup ksiądz proboszcz rabin pop arcybiskup kardynał pastor\n","ryby: karp śledź łosoś dorsz okoń sandacz szczupak płotka\n","napoje_mleczne: jogurt kefir maślanka\n","czynności_sportowe: bieganie skakanie pływanie maszerowanie marsz trucht\n","ubranie:  garnitur smoking frak żakiet marynarka koszula bluzka sweter sweterek sukienka kamizelka spódnica spodnie\n","mebel: krzesło fotel kanapa łóżko wersalka sofa stół stolik ława\n","przestępca: morderca zabójca gwałciciel złodziej bandyta kieszonkowiec łajdak łobuz\n","mięso_wędliny wieprzowina wołowina baranina cielęcina boczek baleron kiełbasa szynka schab karkówka dziczyzna\n","drzewo: dąb klon wiąz jesion świerk sosna modrzew platan buk cis jawor jarzębina akacja\n","źródło_światła: lampa latarka lampka żyrandol żarówka reflektor latarnia lampka\n","organ: wątroba płuco serce trzustka żołądek nerka macica jajowód nasieniowód prostata śledziona\n","oddziały: kompania pluton batalion brygada armia dywizja pułk\n","napój_alkoholowy: piwo wino wódka dżin nalewka bimber wiśniówka cydr koniak wiśniówka\n","kot_drapieżny: puma pantera lampart tygrys lew ryś żbik gepard jaguar\n","metal: żelazo złoto srebro miedź nikiel cyna cynk potas platyna chrom glin aluminium\n","samolot: samolot odrzutowiec awionetka bombowiec myśliwiec samolocik helikopter śmigłowiec\n","owoc: jabłko gruszka śliwka brzoskwinia cytryna pomarańcza grejpfrut porzeczka nektaryna\n","pościel: poduszka prześcieradło kołdra kołderka poduszeczka pierzyna koc kocyk pled\n","agd: lodówka kuchenka pralka zmywarka mikser sokowirówka piec piecyk piekarnik\n","'''"]},{"cell_type":"markdown","id":"70e9e948","metadata":{"id":"70e9e948"},"source":["task a"]},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel\n","import numpy as np\n","from tqdm.auto import tqdm\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f\"Using {device}\")\n","\n","gpt2_model_name = 'gpt2'\n","gpt2_tokenizer = AutoTokenizer.from_pretrained(gpt2_model_name)\n","gpt2_model = AutoModelForCausalLM.from_pretrained(gpt2_model_name).to(device)\n","\n","# non-contextual token embeddings from GPT-2\n","gpt2_embeddings = gpt2_model.transformer.wte.weight.detach().cpu().numpy()\n","print(f\"Embeddings shape: {gpt2_embeddings.shape}\")\n","\n","# unique words\n","words = set()\n","for line in test_words.split('\\n'):\n","    parts = line.split()\n","    if len(parts) < 2:\n","        continue\n","    words.update(parts[1:])\n","\n","print(f\"Unique words: {len(words)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SgOrbbGb9-No","executionInfo":{"status":"ok","timestamp":1767361740924,"user_tz":-60,"elapsed":4344,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"}},"outputId":"2355f5e5-41cc-4783-e457-b9d0e82bf63b"},"id":"SgOrbbGb9-No","execution_count":227,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu\n","Embeddings shape: (50257, 768)\n","Unique words: 288\n"]}]},{"cell_type":"code","execution_count":326,"id":"eb469d46","metadata":{"executionInfo":{"elapsed":115,"status":"ok","timestamp":1767362275046,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"},"user_tz":-60},"id":"eb469d46"},"outputs":[],"source":["def get_non_contextual_word_embedding(word, tokenizer, embeddings, method='mean'):\n","    \"\"\"\n","    Get non-contextual word embedding by aggregating token embeddings\n","    or by isolated transformer hidden states (method='combine').\n","    \"\"\"\n","\n","    # ---------- TOKEN-LEVEL METHODS ----------\n","    tokens = tokenizer.tokenize(' ' + word)\n","    if not tokens:\n","        tokens = tokenizer.tokenize(word)\n","\n","    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","    if not token_ids:\n","        return None\n","\n","    token_embeddings = embeddings[token_ids]  # [T, D]\n","\n","    if method == 'mean':\n","        return token_embeddings.mean(axis=0)\n","\n","    elif method == 'first':\n","        return token_embeddings[0]\n","\n","    elif method == 'weighted':\n","        size = len(token_embeddings)\n","        N = min(4, size)\n","\n","        weights = np.array([0.1, 0.5, 0.8, 1.][-N:])\n","        weights /= weights.sum()\n","\n","        vec = np.zeros(token_embeddings.shape[1])\n","        for i in range(N):\n","            vec += token_embeddings[size - i - 1] * weights[-i-1]\n","\n","        return vec\n","\n","    elif method == 'positional':\n","        D = token_embeddings.shape[1]\n","        pos = np.arange(len(token_embeddings))\n","        pos_enc = np.sin(pos[:, None] / (10000 ** (2 * np.arange(D) / D)))\n","        return (token_embeddings * (1 + 0.1 * pos_enc)).mean(axis=0)\n","\n","    # ---------- TRANSFORMER-LEVEL METHOD ----------\n","    elif method == 'combine':\n","        gpt2_model.eval()\n","\n","        inputs = tokenizer(\n","            ' ' + word,\n","            return_tensors='pt',\n","            add_special_tokens=False\n","        ).to(device)\n","\n","        with torch.no_grad():\n","            outputs = gpt2_model.transformer(\n","                input_ids=inputs[\"input_ids\"],\n","                attention_mask=inputs[\"attention_mask\"],\n","                output_hidden_states=True\n","            )\n","\n","        # hidden_states: tuple[L] of [1, T, D]\n","        hs = torch.stack(outputs.hidden_states).squeeze(1)  # [L, T, D]\n","\n","        # mean of last 4 layers\n","        last4 = hs[-4:].mean(dim=0)                          # [T, D]\n","\n","        vec = last4[-1].cpu().numpy()\n","        return vec / (np.linalg.norm(vec) + 1e-9)\n","\n","    else:\n","        raise ValueError(f\"Unsupported method: {method}\")\n"]},{"cell_type":"code","execution_count":338,"id":"e65c8cef","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["f5b94add35fb4c78a74e3070551b4386","a3810f1e846b4993a3d5279d581da879","a33fb0de5a5242c48eaa63808539b397","b3b7c41c9f9b44e091272ee54750c152","70db635a2ea94fbf99e8d34c99ce4109","00559fa72797476aa1cc4ae81119456e","7a8d6d623e56447ea751c34c9fca6616","7250be7228a4473f8c9d73af89312ab5","a0ec5fc4082643e690fa55d32ce4a611","92a67f5404964244b5a73f97672e178f","12baa0ef9ed740399669a409350baa2f"]},"executionInfo":{"elapsed":36840,"status":"ok","timestamp":1767365094302,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"},"user_tz":-60},"id":"e65c8cef","outputId":"f9781541-3149-4d61-a7d6-2fe72ac2f2ce"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/288 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5b94add35fb4c78a74e3070551b4386"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Generated embeddings for 288/288 words\n"]}],"source":["embeddings_1a = {}\n","for word in tqdm(words):\n","    emb = get_non_contextual_word_embedding(word, gpt2_tokenizer, gpt2_embeddings, method='combine')\n","    if emb is not None:\n","        embeddings_1a[word] = emb\n","\n","print(f\"Generated embeddings for {len(embeddings_1a)}/{len(words)} words\")\n"]},{"cell_type":"code","execution_count":339,"id":"4e28b533","metadata":{"id":"4e28b533","executionInfo":{"status":"ok","timestamp":1767365094355,"user_tz":-60,"elapsed":51,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"}}},"outputs":[],"source":["X = np.stack(list(embeddings_1a.values()))\n","mu = X.mean(axis=0)\n","\n","# subtract + normalize\n","for w in embeddings_1a:\n","    v = embeddings_1a[w] - mu\n","    embeddings_1a[w] = v / (np.linalg.norm(v) + 1e-9)\n"]},{"cell_type":"code","execution_count":340,"id":"66260fc6","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1767365094356,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"},"user_tz":-60},"id":"66260fc6"},"outputs":[],"source":["def save_embeddings(embeddings_dict, filename):\n","    with open(filename, 'w') as f:\n","        for word, emb in embeddings_dict.items():\n","            # format: word float1 float2 ... floatD\n","            emb_str = ' '.join(map(str, emb))\n","            f.write(f\"{word} {emb_str}\\n\")\n","    print(f\"Saved {len(embeddings_dict)} embeddings to {filename}\")"]},{"cell_type":"code","execution_count":341,"id":"4d5fe161","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128,"status":"ok","timestamp":1767365094482,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"},"user_tz":-60},"id":"4d5fe161","outputId":"3f86985e-44fd-480d-c67c-3fe5062508b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saved 288 embeddings to word_embedings_file.txt\n","Embeddings saved\n"]}],"source":["save_embeddings(embeddings_1a, 'word_embedings_file.txt')\n","print(\"Embeddings saved\")\n"]},{"cell_type":"code","execution_count":342,"id":"DrsKiiEFt-yw","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3523,"status":"ok","timestamp":1767365098006,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"},"user_tz":-60},"id":"DrsKiiEFt-yw","outputId":"8b170811-0bd0-499c-9d45-b2fc543de2cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["PROBLEMS: 0.0\n","Start\n","TOTAL SCORE: 0.61432\n"]}],"source":["!python3 word_emb_evaluation.py"]},{"cell_type":"markdown","id":"781769bc","metadata":{"id":"781769bc"},"source":["task b"]},{"cell_type":"code","execution_count":343,"id":"7693f9c7","metadata":{"executionInfo":{"elapsed":2560,"status":"ok","timestamp":1767365100580,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"},"user_tz":-60},"id":"7693f9c7"},"outputs":[],"source":["bert_model_name = 'distilbert-base-multilingual-cased'\n","bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n","bert_model = AutoModel.from_pretrained(bert_model_name, output_hidden_states=True).to(device)\n","bert_model.eval()\n","\n","def get_contextual_word_embedding(word, tokenizer, model, device, layer=-1):\n","    \"\"\"\n","    Get contextual word embedding from BERT.\n","    Places word in minimal context to get contextual representation.\n","    \"\"\"\n","    text = f\"To jest {word}.\"\n","\n","    inputs = tokenizer(text, return_tensors='pt').to(device)\n","\n","    # get embeddings from specified layer\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        hidden_states = outputs.hidden_states\n","    layer_embedding = hidden_states[layer]\n","\n","    # find the tokens that correspond to the word\n","    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n","\n","    word_tokens = tokenizer.tokenize(word)\n","\n","    word_token_indices = []\n","    for i in range(len(tokens)):\n","        if tokens[i] in ['[CLS]', '[PAD]', '[SEP]']:\n","            continue\n","\n","        # check if this could be the start of our word\n","        match = True\n","        for j, wt in enumerate(word_tokens):\n","            if i + j >= len(tokens) or tokens[i + j] != wt:\n","                match = False\n","                break\n","        if match:\n","            word_token_indices = list(range(i, i + len(word_tokens)))\n","            break\n","\n","    # if we couldn't find the word, just take the middle tokens (skip [CLS])\n","    if not word_token_indices:\n","        word_token_indices = list(range(1, len(tokens) - 1))\n","\n","    # average embeddings of word tokens\n","    if word_token_indices:\n","        word_embedding = layer_embedding[0, word_token_indices, :].mean(dim=0).cpu().numpy()\n","        return word_embedding\n","\n","    return None"]},{"cell_type":"code","execution_count":344,"id":"9ca98b28","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["f706829fc019497c830a836f876b798c","0dc5456d00524f64af7d5d289787f9f5","095d9af8a7df46e189cf991f96002bd8","bf980457a1e648feb9f806a3788d4280","39307f6b31594b8d938f539ae5fba3f2","1f36098b6b354be4be82e948bae70906","0001ff19dd44411a9323e31d1e39f8f1","6c7f3b5010e94f5a962503a41071f430","ab768c7671d74c02a266f9bbffd2d6f3","e4a7778a2b114c22a190d9f5b1f87925","bfaab097216f4b7bac4bab49cbf32c73"]},"executionInfo":{"elapsed":15646,"status":"ok","timestamp":1767365116245,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"},"user_tz":-60},"id":"9ca98b28","outputId":"7403a1a2-b92b-48b9-90d5-925588c731d7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating contextual embeddings:   0%|          | 0/288 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f706829fc019497c830a836f876b798c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Successfully generated embeddings for 288/288 words\n","Saved 288 embeddings to word_embedings_file.txt\n","Embeddings saved!\n"]}],"source":["embeddings_1b = {}\n","for word in tqdm(words, desc=\"Generating contextual embeddings\"):\n","    emb = get_contextual_word_embedding(word, bert_tokenizer, bert_model, device)\n","    if emb is not None:\n","        # normalize embedding\n","        emb = emb / np.linalg.norm(emb)\n","        embeddings_1b[word] = emb\n","\n","print(f\"Successfully generated embeddings for {len(embeddings_1b)}/{len(words)} words\")\n","\n","save_embeddings(embeddings_1b, 'word_embedings_file.txt')\n","print(\"Embeddings saved!\")"]},{"cell_type":"code","execution_count":345,"id":"89ojESWnuOKj","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4835,"status":"ok","timestamp":1767365121081,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"},"user_tz":-60},"id":"89ojESWnuOKj","outputId":"407be987-7e29-489b-a84c-7d182dcb30f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["PROBLEMS: 0.0\n","Start\n","TOTAL SCORE: 0.688636\n"]}],"source":["!python3 word_emb_evaluation.py"]},{"cell_type":"markdown","id":"3e27a4f0","metadata":{"id":"3e27a4f0"},"source":["task c"]},{"cell_type":"code","execution_count":346,"id":"8ab87088","metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1767365121083,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"},"user_tz":-60},"id":"8ab87088"},"outputs":[],"source":["def combine_embeddings(emb_noncontextual, emb_contextual, method='weighted', weight_contextual=0.5):\n","    \"\"\"\n","    Combine non-contextual and contextual embeddings\n","    Methods: 'weighted', 'concat'\n","    \"\"\"\n","    if emb_noncontextual is None or emb_contextual is None:\n","        return None\n","\n","    # normalize\n","    emb_nc = emb_noncontextual / np.linalg.norm(emb_noncontextual)\n","    emb_c = emb_contextual / np.linalg.norm(emb_contextual)\n","\n","    if method == 'weighted':\n","        # weighted average\n","        combined = (1 - weight_contextual) * emb_nc + weight_contextual * emb_c\n","        return combined / np.linalg.norm(combined)\n","    elif method == 'concat':\n","        # concatenation\n","        combined = np.concatenate([emb_nc, emb_c])\n","        return combined / np.linalg.norm(combined)\n","    else:\n","        return emb_nc\n"]},{"cell_type":"code","execution_count":347,"id":"3e079828","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["72766ff9a7834618b691a71274dc829c","e999cc245b2a4d8cb472f979a520079b","e78fb6e79f5a4d229f0dc5ef11dd9f71","7592a01796884cfea4f0bca0fe74ddc8","825d06bd36de4b6ea2d9b55992e168f2","bebd9dafb5704c02ba4efc47a85c57b2","e612e1f136384991a8b867a67f3cd170","1586f4f61130455d8bad84ffa3080bb6","08a5f4a9285442c3b113268d54c6660f","360f3f750e804ced9a533673cc7091ca","4aa13ee59fe2443ea6f8f4cf42b0ea66"]},"executionInfo":{"elapsed":188,"status":"ok","timestamp":1767365121286,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"},"user_tz":-60},"id":"3e079828","outputId":"960ee4cb-35df-41ad-eb98-18a503cbe89b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating combined embeddings:   0%|          | 0/288 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72766ff9a7834618b691a71274dc829c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Successfully generated combined embeddings for 288/288 words\n","Saved 288 embeddings to word_embedings_file.txt\n","Embeddings saved\n"]}],"source":["embeddings_1c = {}\n","for word in tqdm(words, desc=\"Generating combined embeddings\"):\n","    if word in embeddings_1a and word in embeddings_1b:\n","        combined_emb = combine_embeddings(embeddings_1a[word], embeddings_1b[word], method='weighted', weight_contextual=0.5)\n","        if combined_emb is not None:\n","            embeddings_1c[word] = combined_emb\n","\n","print(f\"Successfully generated combined embeddings for {len(embeddings_1c)}/{len(words)} words\")\n","\n","\n","save_embeddings(embeddings_1c, 'word_embedings_file.txt')\n","print(\"Embeddings saved\")\n"]},{"cell_type":"code","execution_count":348,"id":"HSFp2cLTuO5e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3620,"status":"ok","timestamp":1767365124918,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"},"user_tz":-60},"id":"HSFp2cLTuO5e","outputId":"772cebbd-c8b7-4d96-b164-4686e3a20d94"},"outputs":[{"output_type":"stream","name":"stdout","text":["PROBLEMS: 0.0\n","Start\n","TOTAL SCORE: 0.662298\n"]}],"source":["!python3 word_emb_evaluation.py"]},{"cell_type":"markdown","id":"8a381e6a","metadata":{"id":"8a381e6a"},"source":["# Zadanie 2. (6+Xp)\n","\n","W zadaniu tym będziemy zajmować się klasyfikacją recenzji z wykorzystaniem modeli transformer, możesz tu skorzystać z programu z wykładu (`herbert.ipynb`). W tym zadaniu powinieneś użyć trzech modeli:\n","\n","1. Modelu generatywnego, takiego jak Papuga, Polka o wielkości do 1B, który znajduje prawdopodobieństwa tekstu (podobnie, jak na liście 1)\n","2. Kodera typu BERT (np. herbert), jako ekstraktora cech\n","3. Tradycyjnego modelu Machine Learning, który integruje wyniki dwóch poprzednich modeli.\n","\n","Ten model powinieneś wytrenować na zbiorze treningowym recenzji, a testować na testowym.\n","\n","Wartość premii jest równa: `20 × (a − 0.85)`, gdzie `a` to wartość accuracy na zbiorze testowym.\n","\n","Jeżeli chcesz, możesz skorzystać tu również z wyników kolejnego zadania."]},{"cell_type":"code","execution_count":null,"id":"6749d2e5","metadata":{"id":"6749d2e5"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"9d33e7d2","metadata":{"id":"9d33e7d2"},"source":["# Zadanie 3. (8+1p)\n","\n","W tym zadaniu powinieneś sprawdzić, czy augmentacja danych może poprawić wyniki klasyfikacji, w której BERT jest traktowany jako ekstraktor cech. Mamy 3 osobno punktowane procedury generowania nowych wariantów recenzji:\n","\n","**a)** Augmentacja mechaniczna (czyli wprowadzasz jakieś zniekształcenia w tekście, mogą to być na przykład literówki, zmiana wielkości liter, błędy związane z polskimi literami, etc). **(2p)**\n","\n","**b)** Augmentacja modelem generatywnym, na przykład Papugą. Powinieneś generować recenzje, które bazują na oryginalnej recenzji, zachowując jej polarność (czyli to, czy jest pozytywna, czy negatywna). Zwróć uwagę, że „fantazja\" modelu językowego nie musi tu być wadą – tak naprawdę to niekoniecznie w tej procedurze muszą powstawać poprawne teksty. **(3p)**\n","\n","**c)** Ta procedura augmentacji powinna bazować na Word2Vec i zachowywać w miarę możliwości znaczenie tekstu. Należy wybrane słowa zamieniać na słowa bliskoznaczne, w tej samej formie gramatycznej (będzie to dokładniej omówione na kolejnym wykładzie). **(3p)**\n","\n","Przykładowo recenzja:\n","- *Hotel ogólnie bardzo ładny.* mogłaby być zmieniona na *Pensjonat szczególnie bardzo piękny.*\n","- *Polecam wszystkim tego fizjoterapeutę!* na *Rekomenduję wszystkim tego ortopedę!*\n","\n","Konieczne informacje gramatyczne pojawią się na wykładzie 8 (czyli najbliższym).\n","\n","---\n","\n","Każda recenzja powinna posłużyć do wygenerowania K innych recenzji (dobór K to Twoje zadanie), stąd należy generator napisać w ten sposób, by recenzje były tworzone niedeterministycznie.\n","\n","Dla wybranych (lub wszystkich) procedur przeprowadź uczenie na zaugmentowanych danych za pomocą regresji logistycznej. Dodatkowo można uzyskać **1p premii**, jeżeli któraś z procedur da korzyść w porównaniu do oryginalnych danych (tzn. dzięki augmentacji uda się uzyskać lepszy wynik dla danych testowych).\n","\n","W zadaniu do maksimum wlicza się **6p**."]},{"cell_type":"code","execution_count":null,"id":"a55912bd","metadata":{"id":"a55912bd"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":".venv (3.12.12)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f5b94add35fb4c78a74e3070551b4386":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a3810f1e846b4993a3d5279d581da879","IPY_MODEL_a33fb0de5a5242c48eaa63808539b397","IPY_MODEL_b3b7c41c9f9b44e091272ee54750c152"],"layout":"IPY_MODEL_70db635a2ea94fbf99e8d34c99ce4109"}},"a3810f1e846b4993a3d5279d581da879":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00559fa72797476aa1cc4ae81119456e","placeholder":"​","style":"IPY_MODEL_7a8d6d623e56447ea751c34c9fca6616","value":"100%"}},"a33fb0de5a5242c48eaa63808539b397":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7250be7228a4473f8c9d73af89312ab5","max":288,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a0ec5fc4082643e690fa55d32ce4a611","value":288}},"b3b7c41c9f9b44e091272ee54750c152":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92a67f5404964244b5a73f97672e178f","placeholder":"​","style":"IPY_MODEL_12baa0ef9ed740399669a409350baa2f","value":" 288/288 [00:36&lt;00:00,  7.18it/s]"}},"70db635a2ea94fbf99e8d34c99ce4109":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00559fa72797476aa1cc4ae81119456e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a8d6d623e56447ea751c34c9fca6616":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7250be7228a4473f8c9d73af89312ab5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0ec5fc4082643e690fa55d32ce4a611":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"92a67f5404964244b5a73f97672e178f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12baa0ef9ed740399669a409350baa2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f706829fc019497c830a836f876b798c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0dc5456d00524f64af7d5d289787f9f5","IPY_MODEL_095d9af8a7df46e189cf991f96002bd8","IPY_MODEL_bf980457a1e648feb9f806a3788d4280"],"layout":"IPY_MODEL_39307f6b31594b8d938f539ae5fba3f2"}},"0dc5456d00524f64af7d5d289787f9f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f36098b6b354be4be82e948bae70906","placeholder":"​","style":"IPY_MODEL_0001ff19dd44411a9323e31d1e39f8f1","value":"Generating contextual embeddings: 100%"}},"095d9af8a7df46e189cf991f96002bd8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c7f3b5010e94f5a962503a41071f430","max":288,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab768c7671d74c02a266f9bbffd2d6f3","value":288}},"bf980457a1e648feb9f806a3788d4280":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4a7778a2b114c22a190d9f5b1f87925","placeholder":"​","style":"IPY_MODEL_bfaab097216f4b7bac4bab49cbf32c73","value":" 288/288 [00:15&lt;00:00, 20.47it/s]"}},"39307f6b31594b8d938f539ae5fba3f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f36098b6b354be4be82e948bae70906":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0001ff19dd44411a9323e31d1e39f8f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c7f3b5010e94f5a962503a41071f430":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab768c7671d74c02a266f9bbffd2d6f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e4a7778a2b114c22a190d9f5b1f87925":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfaab097216f4b7bac4bab49cbf32c73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72766ff9a7834618b691a71274dc829c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e999cc245b2a4d8cb472f979a520079b","IPY_MODEL_e78fb6e79f5a4d229f0dc5ef11dd9f71","IPY_MODEL_7592a01796884cfea4f0bca0fe74ddc8"],"layout":"IPY_MODEL_825d06bd36de4b6ea2d9b55992e168f2"}},"e999cc245b2a4d8cb472f979a520079b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bebd9dafb5704c02ba4efc47a85c57b2","placeholder":"​","style":"IPY_MODEL_e612e1f136384991a8b867a67f3cd170","value":"Generating combined embeddings: 100%"}},"e78fb6e79f5a4d229f0dc5ef11dd9f71":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1586f4f61130455d8bad84ffa3080bb6","max":288,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08a5f4a9285442c3b113268d54c6660f","value":288}},"7592a01796884cfea4f0bca0fe74ddc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_360f3f750e804ced9a533673cc7091ca","placeholder":"​","style":"IPY_MODEL_4aa13ee59fe2443ea6f8f4cf42b0ea66","value":" 288/288 [00:00&lt;00:00, 10442.61it/s]"}},"825d06bd36de4b6ea2d9b55992e168f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bebd9dafb5704c02ba4efc47a85c57b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e612e1f136384991a8b867a67f3cd170":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1586f4f61130455d8bad84ffa3080bb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08a5f4a9285442c3b113268d54c6660f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"360f3f750e804ced9a533673cc7091ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aa13ee59fe2443ea6f8f4cf42b0ea66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}