{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqOeG98pc0K8"
   },
   "source": [
    "dodaj info o 1pkt za zrobienie na prawdziwym obrazku.\n",
    "popraw zadania o copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5s9Fz2R1c0LC"
   },
   "source": [
    "# Lista 2\n",
    "\n",
    "## Numpy podstawy\n",
    "\n",
    "(9pkt + 3pkt)\n",
    "\n",
    "Na liście znajduje się 9 zadań do wykonania w trakcie zajęć. Po rozwiązaniu zadania pokaż kod prowadzącemu i odpowiedz na **pytanie kontrolne** (są one podane przy każdym zadaniu) — wtedy przyznajemy punkt. Dodatkowo prześlij zadanie na platformie skos.\n",
    "\n",
    "Jeśli w poleceniu nie jest wskazane użycie pętli `for` - nie korzystaj z niej.\n",
    "\n",
    "Zadania dodatkowe są oznaczone ⭐️. To zadani o numerach 10 i 11. Dodatkowo moeżesz otrzymać 1pkt z puli punktów bonusowych jeśli wykonasz wszystkie poniższe zadania związane z obrazami na prawdziwym obrazku.\n",
    "\n",
    "Kazde zadnanie warte jest 1pkt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qP_9Ejwqc0LD"
   },
   "source": [
    "## 1. Analiza pikseli obrazu\n",
    "\n",
    "**Kontekst:** W AI obrazy to tablice NumPy (np. `H×W×C`). Proste operacje na obrazach można robić wektorowo bez pętli.\n",
    "\n",
    "**Polecenie**\n",
    "\n",
    "* Utwórz przykładową tablicę 3×3 obrazu RGB zawierającą wartości 0–255.\n",
    "* Zwiększ jasność o 10% — ale **nie przekraczaj 255** (`np.clip`).\n",
    "* Pokaż wynik i typ danych.\n",
    "\n",
    "**Podpowiedź**\n",
    "Zwiększ jasność obrazu mnożąc każde pasmo RGB przez 110%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1760441258062,
     "user": {
      "displayName": "Patryk Flama",
      "userId": "14474424760527076284"
     },
     "user_tz": -120
    },
    "id": "dlKRW2oMc0LE",
    "outputId": "4fe7c922-a5c9-47e7-812d-b341124fc6f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oryginał:\n",
      " [[  5 196 159]\n",
      " [243 108 221]\n",
      " [ 88 113 240]]\n",
      "Po zwiększeniu jasności o 10%:\n",
      " [[  5 215 174]\n",
      " [255 118 243]\n",
      " [ 96 124 255]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.random.randint(0, 256, (3, 3)) # Uzupełnij\n",
    "bright = np.clip(A*1.1, 0, 255).astype(np.int64) # Uzupełnij\n",
    "\n",
    "print(\"Oryginał:\\n\", A)\n",
    "print(\"Po zwiększeniu jasności o 10%:\\n\", bright)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mWBaZTYc0LH"
   },
   "source": [
    "## 2. Normalizacja danych wejściowych\n",
    "\n",
    "**Kontekst:** Dane wejściowe do modeli zazwyczaj normujemy — albo do `[0,1]`, albo standaryzujemy do średniej 0 i odchylenia 1.\n",
    "\n",
    "**Polecenie**\n",
    "\n",
    "* Wygeneruj 1D tablicę 100 losowych liczb w przedziale `0..255`.\n",
    "* Przeskaluj na `[0,1]`.\n",
    "* Następnie stwórz znormalizowaną wersję z średnią 0 i odchyleniem 1 (standaryzacja).\n",
    "* Nie używaj pętli.\n",
    "\n",
    "**Pytanie kontrolne:** Co się stanie, gdy `std == 0`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1760467990113,
     "user": {
      "displayName": "Patryk Flama",
      "userId": "14474424760527076284"
     },
     "user_tz": -120
    },
    "id": "WTf88LyUc0LH",
    "outputId": "604ce448-7600-45cf-8526-92c4b20ebeda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean scaled: 0.5123921568627451\n",
      "mean standardized: 0.2985528185549888\n",
      "std standardized: [ 1.09469249  0.89766361 -1.09889578 -0.87559637 -0.08748083 -1.25651889\n",
      "  1.5412913  -0.98067844  0.92393413 -0.7705143   0.30657695  0.63495843\n",
      "  0.35911798  0.72690524  1.47561501 -0.28450971  0.47733532  0.70063472\n",
      " -1.24338363 -1.41414199  1.40993871  0.31971221 -1.65057666  0.18835962\n",
      "  0.35911798  0.80571679  0.75317576 -1.16457207  0.28030643  1.48875027\n",
      "  1.40993871  0.52987635  0.01760125 -0.88873163 -1.66371192 -0.36332127\n",
      " -1.5717651   1.47561501 -1.20397785  1.10782775  0.41165902 -0.45526808\n",
      " -0.08748083 -0.73110852  0.83198731  0.87139309  1.35739768 -0.62602645\n",
      " -0.91500215 -1.62430614  1.37053293  0.05700702  0.85825783 -1.11203104\n",
      " -1.37473622 -0.67856749 -1.26965414  0.12268332  1.48875027  0.17522436\n",
      "  1.06842198 -0.29764497  0.6743642   0.59555265 -1.32219518 -0.20569816\n",
      " -0.75737904  0.00446599  0.87139309 -0.04807505 -1.53235933 -1.53235933\n",
      "  0.72690524 -0.98067844 -0.92813741  1.27858612 -1.09889578  0.84512257\n",
      " -1.41414199 -0.7705143  -0.14002186 -1.40100674  0.63495843 -1.33533044\n",
      " -0.94127267 -0.87559637  0.54301161  0.85825783  0.46420006  1.06842198\n",
      " -1.17770733 -0.86246111  1.18663931  1.05528672  1.04215146  1.17350405\n",
      "  1.47561501  0.98961042 -1.55862985  1.18663931]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.randint(0, 256, 100)\n",
    "\n",
    "# skalowanie do [0,1]\n",
    "x_scaled = np.clip(x/255, 0, 1)\n",
    "\n",
    "# standaryzacja: (x - mean)/std\n",
    "mean = np.mean(x_scaled)\n",
    "std = np.std(x_scaled)\n",
    "# gdy std == 0 to mamy dzielenie przez 0, co w wyniku daje +-inf\n",
    "x_standardized = (x_scaled - mean)/std\n",
    "\n",
    "print(\"mean scaled:\", mean)\n",
    "print(\"mean standardized:\", std)\n",
    "print(\"std standardized:\", x_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_w5aASic0LI"
   },
   "source": [
    "## 3. Wycinanie fragmentów danych\n",
    "\n",
    "**Kontekst:** Często dzielimy długi sygnał na krótsze okna (np. do ekstrakcji cech).\n",
    "\n",
    "**Polecenie**\n",
    "\n",
    "* Stwórz 1D tablicę długości 1000 (np. `np.arange(1000)`).\n",
    "* Podziel ją na 10 fragmentów po 100 elementów (`reshape`).\n",
    "* Oblicz średnią każdego fragmentu (wektor 10-elementowy).\n",
    "\n",
    "**Pytanie kontrolne:** Co policzymy jeśli obliczymy `axis=0`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1760441669502,
     "user": {
      "displayName": "Patryk Flama",
      "userId": "14474424760527076284"
     },
     "user_tz": -120
    },
    "id": "BgGRtkZnc0LJ",
    "outputId": "8af221f1-54ec-4f7b-da9e-fe69f044d36a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape chunks: (10, 100)\n",
      "means: [ 49.5 149.5 249.5 349.5 449.5 549.5 649.5 749.5 849.5 949.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.arange(1000)\n",
    "chunks = x.reshape(10, 100)\n",
    "means = np.mean(chunks, axis=1)\n",
    "\n",
    "print(\"shape chunks:\", chunks.shape)\n",
    "print(\"means:\", means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhOdFbboc0LK"
   },
   "source": [
    "## 4. Operacje wzdłuż osi\n",
    "\n",
    "**Kontekst:** Przy normalizacjach i agregacjach często operujemy wzdłuż konkretnej osi.\n",
    "\n",
    "**Polecenie**\n",
    "\n",
    "* Utwórz `X = np.random.randint(0, 100, (5,4))`.\n",
    "* Oblicz:\n",
    "\n",
    "  * min każdego wiersza używając `X.min(...)`\n",
    "  * max każdej kolumny używając `X.max(...)`\n",
    "* Znormalizuj każdy wiersz tak, aby suma elementów w wierszu była równa 1. Sprawdź poprawność rozwiązania sumując wartości w każdym wierszu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1760442239220,
     "user": {
      "displayName": "Patryk Flama",
      "userId": "14474424760527076284"
     },
     "user_tz": -120
    },
    "id": "NekIZyqUc0LK",
    "outputId": "b748c1e6-60c6-4d9f-ebe6-0c8bec97561b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[24 46  7 12]\n",
      " [ 6 74 91 68]\n",
      " [37 74 76 85]\n",
      " [39 13 78 73]\n",
      " [20 93  0 48]]\n",
      "row_mins: [ 7  6 37 13  0]\n",
      "col_maxs: [39 93 91 85]\n",
      "X_norm (suma wiersza): [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.randint(0, 100, (5,4))\n",
    "\n",
    "row_mins = X.min(axis=1)\n",
    "col_maxs = X.max(axis=0)\n",
    "\n",
    "# normalizacja wierszy do sumy 1\n",
    "row_sums = X.sum(axis=1).reshape(5, 1)    # shape (5,1) - jakiego parametru trzeba użyć?\n",
    "X_norm = X / row_sums\n",
    "\n",
    "print(\"X:\\n\", X)\n",
    "print(\"row_mins:\", row_mins)\n",
    "print(\"col_maxs:\", col_maxs)\n",
    "print(\"X_norm (suma wiersza):\", X_norm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnDHfH_2c0LL"
   },
   "source": [
    "## 5. Analiza embeddingów słów\n",
    "\n",
    "**Kontekst:** W NLP słowa reprezentujemy wektorami (embeddingi). Często chcemy średnią reprezentację zdania i podobieństwo kosinusowe.\n",
    "\n",
    "**Polecenie**\n",
    "\n",
    "* Stwórz macierz `E` o kształcie `(5,50)` — 5 embeddingów po 50 wymiarów (`np.random.randn`).\n",
    "* Oblicz:\n",
    "\n",
    "  * `mean_embedding` (średni wektor po wierszach)\n",
    "  * macierz podobieństw kosinusowych między wszystkimi parami wektorów (5×5)\n",
    "\n",
    "**Pytanie kontrolne:** Jak interpretujesz wartości w `cosine_sim` (zakres i znaczenie)?\n",
    "\n",
    "---\n",
    "\n",
    "### Wskazówka\n",
    "\n",
    "Zastanów się, jak można obliczyć **podobieństwo kosinusowe** dwóch wektorów `a` i `b`, jeśli wiesz, że:\n",
    "\n",
    "$$\n",
    "\\cos(\\theta) = \\frac{a \\cdot b}{|a| \\cdot |b|}\n",
    "$$\n",
    "\n",
    "Spróbuj najpierw policzyć to dla jednej pary wektorów w NumPy,\n",
    "używając `np.dot()` i `np.linalg.norm()`.\n",
    "\n",
    "A następnie pomyśl:\n",
    "\n",
    "* Jak znormalizować wszystkie wektory jednocześnie, żeby każdy miał długość 1?\n",
    "* Jak wykorzystać mnożenie macierzy (`@`), żeby w jednym kroku dostać podobieństwa między wszystkimi parami wektorów (5×5)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1760469614642,
     "user": {
      "displayName": "Patryk Flama",
      "userId": "14474424760527076284"
     },
     "user_tz": -120
    },
    "id": "gKSzRsF2c0LL",
    "outputId": "1a5b0cf4-45a7-453b-c73a-0d20c23586e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.13910853531887638\n",
      "mean_embedding shape: (50,)\n",
      "cosine_sim shape: (5, 5)\n",
      "cosine_sim (przykład):\n",
      " [[ 1.         -0.13910854 -0.23545391 -0.14678445 -0.08550306]\n",
      " [-0.13910854  1.          0.14122223 -0.14158484  0.06081683]\n",
      " [-0.23545391  0.14122223  1.          0.02608373  0.04997289]\n",
      " [-0.14678445 -0.14158484  0.02608373  1.          0.01588249]\n",
      " [-0.08550306  0.06081683  0.04997289  0.01588249  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# cosine sim to cosinusowe podobieństwo między każdą parą wektorów\n",
    "# dlatego na przekątnej mamy 1 - wektor jest identyczny ze sobą\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "E = np.random.randn(5, 50)\n",
    "\n",
    "# średni wektor (embedding zdania)\n",
    "mean_embedding = np.mean(E, axis=0)\n",
    "\n",
    "a = E[0]\n",
    "b = E[1]\n",
    "print(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))\n",
    "\n",
    "# normalizacja wektorów do długości 1\n",
    "norms = np.linalg.norm(E, axis=1).reshape(5, 1)\n",
    "E_normalized = E / norms\n",
    "\n",
    "# macierz podobieństw kosinusowych = E_norm @ E_norm.T\n",
    "cosine_sim = E_normalized @ E_normalized.T\n",
    "\n",
    "print(\"mean_embedding shape:\", mean_embedding.shape)\n",
    "print(\"cosine_sim shape:\", cosine_sim.shape)\n",
    "print(\"cosine_sim (przykład):\\n\", cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7QFw9L_c0LM"
   },
   "source": [
    "## 6. Sklejanie sensorów — dane z pojazdu autonomicznego\n",
    "\n",
    "**Kontekst:** Dane z różnych sensorów różnią się formatem — trzeba je połączyć w jedną macierz cech.\n",
    "\n",
    "**Polecenie**\n",
    "\n",
    "* Stwórz:\n",
    "\n",
    "  ```python\n",
    "  lidar = np.random.rand(100, 2)   # x,y # lidar - Light Detection and Ranging\n",
    "  camera = np.random.rand(100, 1)  # jasność\n",
    "  radar = np.random.rand(100, 1)   # prędkość\n",
    "  ```\n",
    "* Połącz je kolumnowo w macierz `X` o kształcie `(100,4)`.\n",
    "* Podziel `X` na `train` (80%) i `test` (20%) (np. `np.array_split` lub indeksowanie).\n",
    "* Oblicz średnią jasność i średnią prędkość dla obu zestawów.\n",
    "\n",
    "**Pytanie kontrolne:** Dlaczego warto przetasować dane (shuffle) przed splitem w prawdziwym pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1760442813846,
     "user": {
      "displayName": "Patryk Flama",
      "userId": "14474424760527076284"
     },
     "user_tz": -120
    },
    "id": "_AvGa1Cbc0LN",
    "outputId": "da3fb05d-f991-4a6b-c87b-eebe0ffa9df4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (100, 4)\n",
      "train/test shapes: (80, 4) (20, 4)\n",
      "mean camera train/test: 0.5280871093572775 0.6106467803774331\n",
      "mean radar train/test: 0.5426740790312261 0.574587972350673\n"
     ]
    }
   ],
   "source": [
    "# normalnie tasujemy dane, bo nie wiemy w jakim rozkładzie są one w datasecie\n",
    "# np możemy najpierw mieć pozytywne, później negatywne próbki, więc testujemy tylko na negatywnych\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "lidar = np.random.rand(100, 2)   # x,y\n",
    "camera = np.random.rand(100, 1)  # jasność\n",
    "radar = np.random.rand(100, 1)   # prędkość\n",
    "\n",
    "X = np.hstack((lidar, camera, radar))\n",
    "assert X.shape == (100, 4)\n",
    "\n",
    "# split train/test (bez shuffle dla prostoty)\n",
    "n_train = np.floor(0.8*len(X)).astype(np.int32)\n",
    "train, test = np.vsplit(X, (n_train,))\n",
    "\n",
    "# indeksy kolumn: camera -> 2, radar -> 3 (0-based)\n",
    "mean_camera_train = np.mean(train[:, 2])\n",
    "mean_radar_train = np.mean(train[:, 3])\n",
    "mean_camera_test = np.mean(test[:, 2])\n",
    "mean_radar_test = np.mean(test[:, 3])\n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"train/test shapes:\", train.shape, test.shape)\n",
    "print(\"mean camera train/test:\", mean_camera_train, mean_camera_test)\n",
    "print(\"mean radar train/test:\", mean_radar_train, mean_radar_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f81S-r0zc0LN"
   },
   "source": [
    "## 7. NumPy vs. czysty Python\n",
    "\n",
    "**Kontekst:** NumPy działa o wiele szybciej niż pętle Pythonowe dla operacji numerycznych. Tu wykorzystamy `np.linspace`.\n",
    "\n",
    "**Polecenie**\n",
    "\n",
    "* Stwórz `x = np.linspace(0, 1, 10_000_000)`.\n",
    "* Oblicz `s = sin(x)**2 + cos(x)**2`:\n",
    "\n",
    "  * a) w czystym Pythonie (pętla `for` i `math.sin`, `math.cos`)\n",
    "  * b) w NumPy (`np.sin`, `np.cos` — wektoryzacja)\n",
    "* Porównaj czasy wykonania (wskazane: `%timeit` w notebooku lub `time.time()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5900,
     "status": "ok",
     "timestamp": 1760442885118,
     "user": {
      "displayName": "Patryk Flama",
      "userId": "14474424760527076284"
     },
     "user_tz": -120
    },
    "id": "4E-uPm-fc0LN",
    "outputId": "84b3dddd-ecd1-487b-d7d2-57c94a94bf8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy time: 0.313s\n",
      "Pure Python loop time: 5.643s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "# dane\n",
    "x = np.linspace(0, 1, 10_000_000)\n",
    "\n",
    "# NumPy version\n",
    "t0 = time.time()\n",
    "y_np = np.sin(x)**2 + np.cos(x)**2\n",
    "t_np = time.time() - t0\n",
    "\n",
    "# Python loop version (bardzo wolne; uruchamiaj ostrożnie; jak trwa dłuej ni 15s, to przerwij i zmniejsz przykład)\n",
    "t0 = time.time()\n",
    "s = 0.0\n",
    "for xi in x:\n",
    "    s += math.sin(xi)**2 + math.cos(xi)**2\n",
    "t_py = time.time() - t0\n",
    "\n",
    "print(f\"NumPy time: {t_np:.3f}s\")\n",
    "print(f\"Pure Python loop time: {t_py:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpiT4Fauc0LO"
   },
   "source": [
    "## 8. Copy, View\n",
    "\n",
    "**Kontekst:** Podczas preprocessingu zespoły czasami pracują na tym samym obiekcie myśląc, że mają kopię — to prowadzi do skażenia danych.\n",
    "\n",
    "**Polecenie**\n",
    "\n",
    "* Stwórz `patients = np.random.randint(60, 120, (5, 4))`.\n",
    "  * `doctors_view`, gdzie doktor będzie przeglądał tylko co drugi pomiar,\n",
    "  * `research_copy`, czyli kopię patients.\n",
    "* Lekarz przez pomyłkę wykona `doctors_view[:] = -1`.\n",
    "* Sprawdź, czy `patients` się zmieniło i czy `research_copy` pozostało bez zmian. Wyjaśnij.\n",
    "\n",
    "**Pytanie kontrolne:** W jaki sposób zabezpieczyć workflow, żeby przypadkowe zmiany nie wpływały na bazę danych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1760442956899,
     "user": {
      "displayName": "Patryk Flama",
      "userId": "14474424760527076284"
     },
     "user_tz": -120
    },
    "id": "r-vr8Gtyc0LO",
    "outputId": "8920c401-737c-4738-891c-b6eff27cb834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "przed zmiana:\n",
      " [[ 74 114 117  89]\n",
      " [ 90  89  98 119]\n",
      " [116  98  92 104]\n",
      " [ 68 117  73  92]\n",
      " [ 61  88  93  68]]\n",
      "po zmianie doctors_view:\n",
      " [[-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]]\n",
      "research_copy (czy zmienione?):\n",
      " [[ 74 114 117  89]\n",
      " [ 90  89  98 119]\n",
      " [116  98  92 104]\n",
      " [ 68 117  73  92]\n",
      " [ 61  88  93  68]]\n",
      "doctors_view.base is patients? True\n",
      "research_copy.base is patients? False\n"
     ]
    }
   ],
   "source": [
    "# aby zabezpieczyć bazę danych powinniśmy zawsze pracować na kopii danych\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "patients = np.random.randint(60, 120, (5, 4))\n",
    "doctors_view = patients.view()\n",
    "research_copy = patients.copy()\n",
    "\n",
    "print(\"przed zmiana:\\n\", patients)\n",
    "doctors_view[:] = -1\n",
    "print(\"po zmianie doctors_view:\\n\", patients)\n",
    "print(\"research_copy (czy zmienione?):\\n\", research_copy)\n",
    "\n",
    "# wykrywamy, które są view / copy\n",
    "print(\"doctors_view.base is patients?\", doctors_view.base is patients)\n",
    "print(\"research_copy.base is patients?\", research_copy.base is patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApapobHvc0LP"
   },
   "source": [
    "## 9. Jak CNN „przesuwa okno” po obrazie?\n",
    "\n",
    "**Kontekst:** W konwolucyjnej sieci neuronowej filtr (np. 3×3) „przesuwa się” po obrazie piksel po pikselu. Parametr stride określa, o ile pikseli filtr przesuwa się w pamięci między kolejnymi pozycjami. Zrozumienie, jak numpy.strides działa, pozwala intuicyjnie pojąć, dlaczego operacja konwolucji może być wydajna bez kopiowania danych.\n",
    "\n",
    "**Polecenie**\n",
    "\n",
    "1. Utwórz: `A = np.arange(1,13).reshape(3,4)` — traktuj jako obraz `3 × 4`, oraz `AT = A.T`.\n",
    "2. Wypisz: `A`, `A.strides`, `AT`, `AT.strides`.\n",
    "3. Oblicz ile bajtów trzeba przeskoczyć, aby dotrzeć:\n",
    "   * od `A[0,0]` do `A[0,1]`,\n",
    "   * od `A[0,0]` do `A[1,0]`.\n",
    "4. Sprawdź, czy `AT` jest widokiem (`AT.base is A`), zmień `A[0,0] = -99` i sprawdź `AT`.\n",
    "5. Napisz funkcję `memory_offset(A, i, j)`, która obliczy ile bajtów trzeba przejść od `A[0][0]` do miejsca `A[i][j]`\n",
    "   Użyj jej, żeby policzyć offsety kilku elementów w `A` i `A.T`. Zinterpretuj wyniki.\n",
    "\n",
    "**Pytanie kontrolne:** Wyjaśnij własnymi słowami: co się stanie jak zmienisz `strides`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1760443517447,
     "user": {
      "displayName": "Patryk Flama",
      "userId": "14474424760527076284"
     },
     "user_tz": -120
    },
    "id": "RKJeRwQBc0LP",
    "outputId": "df350959-cfc1-4ae4-dbf7-7b872022e1c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "A.strides: (32, 8)\n",
      "AT:\n",
      " [[ 1  5  9]\n",
      " [ 2  6 10]\n",
      " [ 3  7 11]\n",
      " [ 4  8 12]]\n",
      "AT.strides: (8, 32)\n",
      "itemsize (bajtów per element): 32\n",
      "offset A[0,0] -> A[0,1] (bajtów): 256\n",
      "offset A[0,0] -> A[1,0] (bajtów): 1024\n",
      "A.T.base is A ? False\n",
      "A po zmianie:\n",
      " [[-99   2   3   4]\n",
      " [  5   6   7   8]\n",
      " [  9  10  11  12]]\n",
      "A.T po zmianie:\n",
      " [[-99   5   9]\n",
      " [  2   6  10]\n",
      " [  3   7  11]\n",
      " [  4   8  12]]\n",
      "memory offset A[2,3]: 2816\n",
      "memory offset AT[2,3]: 3584\n",
      "memory offset A[0,1]: 256\n",
      "memory offset AT[1,0]: 1024\n"
     ]
    }
   ],
   "source": [
    "# jeżeli zmienimy strides zmieniamy to jak numpy widzi dane\n",
    "# zmienimy sposób w jaki numpy porusza się po danych\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "A = np.arange(1, 13).reshape(3, 4)\n",
    "print(\"A:\\n\", A)\n",
    "print(\"A.strides:\", A.strides)\n",
    "\n",
    "AT = A.T\n",
    "print(\"AT:\\n\", AT)\n",
    "print(\"AT.strides:\", AT.strides)\n",
    "\n",
    "# elementsize (liczba bajtów na element)\n",
    "bs = sys.getsizeof(A[0][0])\n",
    "print(\"itemsize (bajtów per element):\", bs)\n",
    "\n",
    "# obliczenia ręczne:\n",
    "offset_A_00_to_01 = A.strides[1] * bs\n",
    "offset_A_00_to_10 = A.strides[0] * bs\n",
    "print(\"offset A[0,0] -> A[0,1] (bajtów):\", offset_A_00_to_01)\n",
    "print(\"offset A[0,0] -> A[1,0] (bajtów):\", offset_A_00_to_10)\n",
    "\n",
    "# sprawdzenie widoku\n",
    "print(\"A.T.base is A ?\", AT.base is A)\n",
    "\n",
    "# zmiana A i obserwacja AT\n",
    "A[0,0] = -99\n",
    "print(\"A po zmianie:\\n\", A)\n",
    "print(\"A.T po zmianie:\\n\", AT)\n",
    "\n",
    "# funkcja memory_offset\n",
    "def memory_offset(M, i, j):\n",
    "    return (M.strides[0]*i + M.strides[1]*j) * bs\n",
    "\n",
    "print(\"memory offset A[2,3]:\", memory_offset(A, 2, 3))\n",
    "print(\"memory offset AT[2,3]:\", memory_offset(AT, 2, 3))\n",
    "\n",
    "print(\"memory offset A[0,1]:\", memory_offset(A, 0, 1))\n",
    "print(\"memory offset A[1,0]:\", memory_offset(A, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llPGqhyVc0LQ"
   },
   "source": [
    "## 10. ⭐️ Zaawansowana augmentacja i analiza obrazów RGB\n",
    "\n",
    "**Kontekst:** Przy trenowaniu CNN operujemy na obrazach RGB. Często robimy augmentacje (jasność, kontrast, rotacje, przesunięcia) i porównujemy obrazy np. za pomocą **cosine similarity**. Trzeba uważać, które operacje zwracają **widok**, a które **kopię**, aby nie psuć danych przez przypadek.\n",
    "\n",
    "**Polecenie**\n",
    "\n",
    "1. Wygeneruj **10 losowych obrazów RGB**, każdy o wymiarach `32×32×3` z wartościami `uint8` (0–255).\n",
    "2. Napisz funkcję `cosine_similarity(img1, img2)`, która oblicza podobieństwo kosinusowe między dwoma obrazami traktowanymi jako wektory.\n",
    "3. Stwórz funkcję `augment(img)` która tworzy warianty obrazu:\n",
    "\n",
    "   * oryginał,\n",
    "   * flip poziomy,\n",
    "   * flip pionowy,\n",
    "   * rotacja 90°,\n",
    "   * jaśniejsza wersja,\n",
    "   * wersja z większym kontrastem,\n",
    "   * mały przesunięty fragment (crop + pad),\n",
    "   * zamiana kanałów RGB na BGR.\n",
    "4. Dla każdego wariantu sprawdź, które są **widokiem**, a które **kopią** (`.base`).\n",
    "5. Oblicz macierz podobieństwa kosinusowego między wszystkimi 10 obrazami oryginalnymi i wypisz średnie podobieństwo.\n",
    "6. Oblicz podobieństwo między oryginałami a ich wariantami i sprawdź, które operacje najbardziej zmieniają obraz (najmniejsze cosine similarity).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1760950537983,
     "user": {
      "displayName": "Patryk Flama",
      "userId": "14474424760527076284"
     },
     "user_tz": -120
    },
    "id": "uSIVla43c0LQ",
    "outputId": "70741291-fe6a-4e3a-deaf-8e905ea77f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "[[1.   0.76 0.75 0.74 0.75 0.76 0.74 0.75 0.76 0.76]\n",
      " [0.76 1.   0.74 0.74 0.74 0.74 0.75 0.76 0.75 0.75]\n",
      " [0.75 0.74 1.   0.74 0.75 0.76 0.75 0.75 0.75 0.75]\n",
      " [0.74 0.74 0.74 1.   0.76 0.76 0.75 0.76 0.75 0.75]\n",
      " [0.75 0.74 0.75 0.76 1.   0.75 0.75 0.75 0.76 0.75]\n",
      " [0.76 0.74 0.76 0.76 0.75 1.   0.76 0.75 0.75 0.75]\n",
      " [0.74 0.75 0.75 0.75 0.75 0.76 1.   0.75 0.76 0.74]\n",
      " [0.75 0.76 0.75 0.76 0.75 0.75 0.75 1.   0.76 0.76]\n",
      " [0.76 0.75 0.75 0.75 0.76 0.75 0.76 0.76 1.   0.76]\n",
      " [0.76 0.75 0.75 0.75 0.75 0.75 0.74 0.76 0.76 1.  ]]\n",
      "AVG similarity: 0.7757553297281266\n",
      "original, flip_row, flip_col, rot90, brightness, contrast, crop, bgr, \n",
      "1.0, 0.75, 0.76, 0.75, 0.99, 0.99, 0.25, 0.84, \n",
      "1.0, 0.75, 0.75, 0.75, 0.99, 0.99, 0.23, 0.84, \n",
      "1.0, 0.74, 0.74, 0.74, 0.99, 0.99, 0.22, 0.83, \n",
      "1.0, 0.74, 0.74, 0.74, 0.99, 0.99, 0.22, 0.82, \n",
      "1.0, 0.74, 0.75, 0.75, 0.99, 0.99, 0.24, 0.83, \n",
      "1.0, 0.75, 0.75, 0.75, 0.99, 0.99, 0.24, 0.84, \n",
      "1.0, 0.75, 0.75, 0.74, 0.99, 0.99, 0.23, 0.84, \n",
      "1.0, 0.75, 0.75, 0.77, 0.99, 0.98, 0.23, 0.84, \n",
      "1.0, 0.77, 0.76, 0.75, 0.99, 0.98, 0.24, 0.84, \n",
      "1.0, 0.75, 0.76, 0.75, 0.99, 0.99, 0.23, 0.83, \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(img1, img2):\n",
    "    img1_flat = img1.view().reshape(-1).astype(np.float32)\n",
    "    img2_flat = img2.view().reshape(-1).astype(np.float32)\n",
    "\n",
    "    similarity = (np.dot(img1_flat, img2_flat)) / (np.linalg.norm(img1_flat) * np.linalg.norm(img2_flat) + 1e-8)\n",
    "    return similarity\n",
    "\n",
    "def contrast(img):\n",
    "    # return a new array with increased contrast (uint8)\n",
    "    img = img.astype(np.float32)\n",
    "    min_val = np.percentile(img, 20)\n",
    "    max_val = np.percentile(img, 80)\n",
    "    img = np.clip(img, min_val, max_val)\n",
    "    img = ((img - min_val) / (max_val - min_val + 1e-8)) * 255\n",
    "    return np.clip(img, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def augment(img):\n",
    "    cropped_img = img[10:20, 10:20]\n",
    "    padded_cropped_img = np.pad(cropped_img, (\n",
    "        (0, 32 - cropped_img.shape[0]),\n",
    "        (0, 32 - cropped_img.shape[1]),\n",
    "        (0, 0)), mode='constant')\n",
    "\n",
    "    return [\n",
    "        img,    # original\n",
    "        np.flip(img, axis=0),   # row-wise flip\n",
    "        np.flip(img, axis=1),   # column-wise flip\n",
    "        np.rot90(img),          # rotation 90\n",
    "        np.clip(img.astype(np.float32)*1.5, 0, 255).astype(np.uint8),   # brightness\n",
    "        contrast(img), # contrast\n",
    "        padded_cropped_img,  # crop\n",
    "        img[:, :, [2, 1, 0]]   # BGR\n",
    "    ]\n",
    "\n",
    "\n",
    "imgs = np.random.randint(0, 256, (10, 32, 32, 3), dtype=np.uint8)\n",
    "augmented_imgs = [augment(imgs[idx]) for idx in range(len(imgs))]\n",
    "\n",
    "for aug_img in augmented_imgs[0]:\n",
    "    print(aug_img.base is imgs[0])\n",
    "\n",
    "similarities = np.zeros((10, 10))\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        similarities[i, j] = cosine_similarity(imgs[i], imgs[j])\n",
    "\n",
    "print(np.round(similarities, 2))\n",
    "print(\"AVG similarity:\", np.mean(similarities))\n",
    "\n",
    "\n",
    "names = [\"original\", \"flip_row\", \"flip_col\", \"rot90\", \"brightness\", \"contrast\", \"crop\", \"bgr\"]\n",
    "for name in names: print(name, end=\", \")\n",
    "print()\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    original_img = imgs[i]\n",
    "    for aug_img in augmented_imgs[i]:\n",
    "        print(np.round(cosine_similarity(original_img, aug_img), 2), end=\", \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPnWeafJc0LR"
   },
   "source": [
    "## 11. ⭐️ Świadome kopiowanie\n",
    "\n",
    "**Kontekst**\n",
    "Pracujesz z dużymi macierzami w Pythonie/NumPy, które reprezentują np. wyniki eksperymentów, symulacje lub dane użytkowników.\n",
    "\n",
    "**Polecenie**\n",
    "Twoim zadaniem jest zdecydować w jaki sposób należy **modyfikować dane**, w miejscu, w kopii, czy wystarczy widok? A może trzeba użyć deepcopy? Rozważ dwa przypadki - kiedy używasz biblioteki `numpy` i `copy`. Odpowiedz na wszystkie pytania. W każdej części musisz **uzasadnić wybór metody**.\n",
    "\n",
    "Na początku stwórz dwuwymiarową tablicę `M`, na której będziesz demonstrować i uzasadniać użycie wybranej metody.\n",
    "\n",
    "#### **a) Lokalna korekta**\n",
    "\n",
    "Wartość w komórce `[0,0]` jest błędna i powinna być `1`.\n",
    "\n",
    "* Jak poprawisz tę wartość?\n",
    "* Czy zmieniasz oryginał, czy tworzysz kopię?\n",
    "* Jak działa pamięć w tym przypadku?\n",
    "\n",
    "#### **b) Alternatywna wersja danych**\n",
    "\n",
    "Chcesz stworzyć **zmodyfikowaną wersję danych**, np. w kolumnie 2 przeskalować wszystkie wartości, w celu przeprowadzenia eksperymentu.\n",
    "\n",
    "* Zastanów się, czy potrzebujesz `view`, `copy` czy `deepcopy`.\n",
    "* Przetestuj różne podejścia (`M.view()`, `M.copy()`) i sprawdź, co się dzieje po modyfikacji nowej macierzy.\n",
    "\n",
    "#### **c) Symulacje z listą zagnieżdżoną**\n",
    "\n",
    "Tworzysz listę eksperymentów:\n",
    "\n",
    "```python\n",
    "L = [M, M.copy()]\n",
    "```\n",
    "\n",
    "Teraz chcesz **przeprowadzić symulacje zmian**, np. dodając losowe wartości, **bez zmiany oryginału** ani kopii w `L`.\n",
    "\n",
    "* Jakiego rodzaju kopiowania użyjesz?\n",
    "* Co się stanie, jeśli użyjesz tylko `copy` zamiast `deepcopy`, gdy struktura jest zagnieżdżona?\n",
    "\n",
    "#### **d) Podzbiór kolumn**\n",
    "\n",
    "Wybierasz podzbiór kolumn np. 1 i 3:\n",
    "\n",
    "```python\n",
    "subset = M[:, [1, 3]]\n",
    "```\n",
    "\n",
    "* Sprawdź, czy zmiany w `subset` wpływają na `M`.\n",
    "* Porównaj to z cięciem typu `subset = M[:, 1:3]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M przed zmianą:\n",
      " [[1 1 1 4]\n",
      " [7 3 1 6]\n",
      " [1 0 6 0]\n",
      " [1 4 3 7]]\n",
      "M2 po zmianie:\n",
      " [[ 1 10  1  4]\n",
      " [ 7 30  1  6]\n",
      " [ 1  0  6  0]\n",
      " [ 1 40  3  7]]\n",
      "M2_view po zmianie:\n",
      " [[  1  30   1   4]\n",
      " [  7  90   1   6]\n",
      " [  1   0   6   0]\n",
      " [  1 120   3   7]]\n",
      "L przed zmianą:\n",
      " [array([[  1,  30,   1,   4],\n",
      "       [  7,  90,   1,   6],\n",
      "       [  1,   0,   6,   0],\n",
      "       [  1, 120,   3,   7]]), array([[  1,  30,   1,   4],\n",
      "       [  7,  90,   1,   6],\n",
      "       [  1,   0,   6,   0],\n",
      "       [  1, 120,   3,   7]])]\n",
      "L_copy po zmianie:\n",
      " [array([[-100,   30,    1,    4],\n",
      "       [   7,   90,    1,    6],\n",
      "       [   1,    0,    6,    0],\n",
      "       [   1,  120,    3,    7]]), array([[  1,  30,   1,   4],\n",
      "       [  7,  90,   1,   6],\n",
      "       [  1,   0,   6,   0],\n",
      "       [  1, 120,   3,   7]])]\n",
      "L_ref po zmianie:\n",
      " [array([[  1,  30,   1,   4],\n",
      "       [  7,  90,   1,   6],\n",
      "       [  1,   0,   6,   0],\n",
      "       [  1, 120,   3,   7]]), array([[-200,   30,    1,    4],\n",
      "       [   7,   90,    1,    6],\n",
      "       [   1,    0,    6,    0],\n",
      "       [   1,  120,    3,    7]])]\n",
      "M przed zmianą subset:\n",
      " [[  1  30   1   4]\n",
      " [  7  90   1   6]\n",
      " [  1   0   6   0]\n",
      " [  1 120   3   7]]\n",
      "M po zmianie subset:\n",
      " [[  1  30   1   4]\n",
      " [  7  90   1   6]\n",
      " [  1   0   6   0]\n",
      " [  1 120   3   7]]\n",
      "M po zmianie subset_slice:\n",
      " [[  1 -75   1   4]\n",
      " [  7 -75   1   6]\n",
      " [  1 -75   6   0]\n",
      " [  1 -75   3   7]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "M = np.random.randint(0, 10, (4,4))\n",
    "\n",
    "# #### **a) Lokalna korekta**\n",
    "\n",
    "# Wartość w komórce `[0,0]` jest błędna i powinna być `1`.\n",
    "\n",
    "# * Jak poprawisz tę wartość?\n",
    "# * Czy zmieniasz oryginał, czy tworzysz kopię?\n",
    "# * Jak działa pamięć w tym przypadku?\n",
    "\n",
    "# nie robimy kopii, bo wartość jest błędna i chcemy ją poprawić w oryginale\n",
    "M[0, 0] = 1\n",
    "\n",
    "\n",
    "# #### **b) Alternatywna wersja danych**\n",
    "\n",
    "# Chcesz stworzyć **zmodyfikowaną wersję danych**, np. w kolumnie 2 przeskalować wszystkie wartości, w celu przeprowadzenia eksperymentu.\n",
    "\n",
    "# * Zastanów się, czy potrzebujesz `view`, `copy` czy `deepcopy`.\n",
    "# * Przetestuj różne podejścia (`M.view()`, `M.copy()`) i sprawdź, co się dzieje po modyfikacji nowej macierzy.\n",
    "\n",
    "# chcemy stworzyć nową wersję, wię chcemy zachować oryginalne dane, więc tworzymy kopię wszystkich danych \n",
    "M2 = M.copy()\n",
    "M2_copy = copy.deepcopy(M)\n",
    "\n",
    "M2[:, 1] = M2[:, 1] * 10  # skalowanie kolumny 2\n",
    "M2_copy[:, 1] = M2_copy[:, 1] * 20  # skalowanie kolumny 2 jeszcze inaczej\n",
    "\n",
    "print(\"M przed zmianą:\\n\", M)\n",
    "print(\"M2 po zmianie:\\n\", M2)\n",
    "M2_view = M.view()\n",
    "M2_view[:, 1] = M2_view[:, 1] * 30\n",
    "print(\"M2_view po zmianie:\\n\", M2_view)\n",
    "\n",
    "# #### **c) Symulacje z listą zagnieżdżoną**\n",
    "\n",
    "# Tworzysz listę eksperymentów:\n",
    "\n",
    "# ```python\n",
    "# L = [M, M.copy()]\n",
    "# ```\n",
    "\n",
    "# Teraz chcesz **przeprowadzić symulacje zmian**, np. dodając losowe wartości, **bez zmiany oryginału** ani kopii w `L`.\n",
    "\n",
    "# * Jakiego rodzaju kopiowania użyjesz?\n",
    "# * Co się stanie, jeśli użyjesz tylko `copy` zamiast `deepcopy`, gdy struktura jest zagnieżdżona?\n",
    "\n",
    "# chcemy stworzyć pełną kopię L, więc skorzystamy z biblioteki copy (bo L nie jest numpy'owe)\n",
    "# użycie zwykłego copy spowoduje, że wewnętrzne macierze nadal będą referencjami do oryginału lub jego kopii\n",
    "L = [M, M.copy()]\n",
    "L_copy = copy.deepcopy(L)\n",
    "L_ref = copy.copy(L)\n",
    "print(\"L przed zmianą:\\n\", L)\n",
    "L_copy[0][0,0] = -100\n",
    "L_ref[1][0,0] = -200\n",
    "print(\"L_copy po zmianie:\\n\", L_copy)\n",
    "print(\"L_ref po zmianie:\\n\", L_ref)\n",
    "\n",
    "# #### **d) Podzbiór kolumn**\n",
    "\n",
    "# Wybierasz podzbiór kolumn np. 1 i 3:\n",
    "\n",
    "# ```python\n",
    "# subset = M[:, [1, 3]]\n",
    "# ```\n",
    "\n",
    "# * Sprawdź, czy zmiany w `subset` wpływają na `M`.\n",
    "# * Porównaj to z cięciem typu `subset = M[:, 1:3]`.\n",
    "\n",
    "\n",
    "subset = M[:, [1, 3]]\n",
    "subset_slice = M[:, 1:3]\n",
    "\n",
    "print(\"M przed zmianą subset:\\n\", M)\n",
    "subset[:, 0] = -50\n",
    "print(\"M po zmianie subset:\\n\", M)\n",
    "subset_slice[:, 0] = -75\n",
    "print(\"M po zmianie subset_slice:\\n\", M)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "numpy_lab (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
