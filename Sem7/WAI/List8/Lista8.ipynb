{"cells":[{"cell_type":"markdown","metadata":{"id":"_a3rPdwIAJcp"},"source":["# Lista 8\n","\n","## PyTorch\n","\n","(6pkt + 2pkt)\n","\n","Na liÅ›cie znajduje siÄ™ 1 zadanie. Po rozwiÄ…zaniu go, pokaÅ¼ kod prowadzÄ…cemu i odpowiedz na **pytanie kontrolne** â€” tylko wtedy przyznajemy punkty. Dodatkowo przeÅ›lij zadanie na platformie skos.\n","\n","Dodatkowe zadanie oznaczone jest â­ï¸ i jest warte 2pkt."]},{"cell_type":"markdown","metadata":{"id":"FRFL26OMAJcr"},"source":["## JeÅ›li Ä‡wiczenia bÄ™dÄ… siÄ™ przedÅ‚uaÅ‚y...\n","\n","Odpowiedz na ponisze pytania pisemnie i przeÅ›lij zadanie na skos. Do zobaczenia na kolejnych zajÄ™ciach! ðŸ˜€\n","\n","1. (W tym pytaniu nie ma zÅ‚ej odpowiedzi, jeÅ›li umiesz jÄ… uzasadniÄ‡) Zbiorem danych sÄ… obrazki, na ktÃ³rych sÄ… napisane cyfry. Jakie transformacje moznaby zastosowaÄ‡ na obrazkach, za pomocÄ… ktÃ³rych bÄ™dziemy uczyli potem sieÄ‡?\n","2. Czy w sieci neuronowej dla ponizszego zbioru danych i dla tej konkretnej architektury potrzebne jest `Flatten`? Dlaczego?\n","3. W zeszÅ‚ym tygodniu omawialiÅ›my Cross Validation. Jak wyglÄ…daÅ‚oby ono w przypadku uczenia sieci neuronowej?"]},{"cell_type":"markdown","metadata":{"id":"ck-0c1m6AJct"},"source":["## Wytrenuj sieÄ‡ neuronowÄ…\n","\n","Twoim celem jest przygotowaÄ‡ kompletny pipeline do trenowania prostej sieci neuronowej w PyTorchu: od datasetu, przez dataloadery i model, aÅ¼ po trening, walidacjÄ™ i test.\n","\n","---\n","\n","### Dataset i transformacje\n","\n","Przygotuj dane wejÅ›ciowe korzystajÄ…c z `torchvision.datasets.MNIST`.\n","\n","#### Kroki:\n","\n","1. Zaimportuj konieczne biblioteki:\n","\n","   * `torch`\n","   * `torchvision`\n","   * `torch.utils.data`\n","   * oraz moduÅ‚ transformacji: `torchvision.transforms as transforms`\n","\n","2. Pobierz dataset **MNIST** dla:\n","\n","   * zbioru treningowego,\n","   * zbioru testowego.\n","\n","3. Zastosuj transformacje:\n","\n","   * **obowiÄ…zkowo:** `transforms.ToTensor()`\n","   * **opcjonalnie:** normalizacja\n","     `transforms.Normalize((0.5,), (0.5,))`\n","\n","4. Podziel zbiÃ³r treningowy na dwie czÄ™Å›ci przy uÅ¼yciu `torch.utils.data.random_split`:\n","\n","   * **90%** â€” train\n","   * **10%** â€” validation\n","\n","5. **Nie twÃ³rz wÅ‚asnego datasetu.** UÅ¼yj wbudowanego `torchvision.datasets.MNIST`.\n","\n","**Uwaga:** Upewnij siÄ™, Å¼e rozmiar batcha to `(batch, 1, 28, 28)` â€” transformacje nie mogÄ… zmieniaÄ‡ tego formatu.\n","\n","---\n","\n","### Dataloadery\n","\n","UtwÃ³rz trzy `DataLoader`-y:\n","\n","* **train** â€” `shuffle=True`\n","* **validation** â€” `shuffle=False`\n","* **test** â€” `shuffle=False`\n","\n","Z parametrami:\n","\n","* `batch_size = 64`\n","* `num_workers = 0`\n","  (Å¼eby uniknÄ…Ä‡ problemÃ³w np. na Windowsowych laptopach)\n","\n","---\n","\n","### SieÄ‡ neuronowa (MLP)\n","\n","Zaimplementuj model dziedziczÄ…c po `nn.Module`.\n","\n","#### Architektura â€” dokÅ‚adnie w tej kolejnoÅ›ci:\n","\n","1. `Flatten()`\n","2. `Linear(28*28, 256)`\n","3. `ReLU()`\n","4. `Linear(256, 128)`\n","5. `ReLU()`\n","6. `Linear(128, 10)`\n","\n","**WskazÃ³wki:**\n","\n","* Warstwy umieÅ›Ä‡ w `nn.Sequential`.\n","* DomyÅ›lna aktywacja to ReLU (ale moÅ¼esz eksperymentowaÄ‡).\n","\n","#### Dodatkowe elementy:\n","\n","1. Funkcja straty: **CrossEntropyLoss**.\n","2. Optymalizator: **Adam**, `lr=0.001`.\n","\n","---\n","\n","### PÄ™tla treningowa\n","\n","Napisz pÄ™tlÄ™ uczÄ…cÄ…, ktÃ³ra dla kaÅ¼dej epoki:\n","\n","#### W trybie `model.train()`:\n","\n","Dla kaÅ¼dego batcha:\n","\n","* oblicza logitsy (predykcje),\n","* oblicza stratÄ™,\n","* wykonuje:\n","\n","  * `optimizer.zero_grad()`\n","  * `loss.backward()`\n","  * `optimizer.step()`\n","* liczy poprawne odpowiedzi.\n","\n","#### Po epce â€” wyÅ›wietl:\n","\n","* Å›redni **train loss**\n","* **train accuracy**\n","\n","**WskazÃ³wka (accuracy):**\n","\n","```python\n","pred = logits.argmax(dim=1)\n","correct += (pred == y).sum().item()\n","```\n","\n","---\n","\n","### Walidacja + zapis najlepszego modelu\n","\n","Dodaj funkcjÄ™ walidujÄ…cÄ…:\n","\n","* `model.eval()`\n","* `torch.no_grad()`\n","\n","Policz:\n","\n","* Å›redni **val loss**\n","* **val accuracy**\n","\n","#### Po kaÅ¼dej epoce:\n","\n","* sprawdÅº, czy `val_loss` jest najlepszy w historii,\n","* jeÅ›li tak â€” zapisz model:\n","\n","```python\n","torch.save(model.state_dict(), \"best_model.pth\")\n","```\n","\n","* wypisz komunikat:\n","\n","> **\"Zapisano nowy najlepszy model!\"**\n","\n","---\n","\n","### Testowanie najlepszego modelu\n","\n","1. Wczytaj najlepsze wagi:\n","\n","   ```python\n","   model.load_state_dict(torch.load(\"best_model.pth\"))\n","   ```\n","\n","2. PrzeprowadÅº ewaluacjÄ™ na zbiorze **testowym** (procedura taka jak przy walidacji).\n","\n","3. WyÅ›wietl **finalnÄ… test accuracy**."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tqp4RgzeAJcv","executionInfo":{"status":"ok","timestamp":1764679734856,"user_tz":-60,"elapsed":48921,"user":{"displayName":"Patryk Flama","userId":"14474424760527076284"}},"outputId":"29f680e1-cc6e-42e1-9789-f09a233fe592"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Error: \n"," Accuracy: 94.0%, Avg loss: 0.188643 \n","\n","Epoch 1/3\n","  Train loss: 0.3612, acc: 0.8913\n","  Val loss:   0.1886, acc: 0.9395\n","Zapisano nowy najlepszy model!\n","Test Error: \n"," Accuracy: 95.7%, Avg loss: 0.129200 \n","\n","Epoch 2/3\n","  Train loss: 0.1669, acc: 0.9493\n","  Val loss:   0.1292, acc: 0.9572\n","Zapisano nowy najlepszy model!\n","Test Error: \n"," Accuracy: 96.2%, Avg loss: 0.111807 \n","\n","Epoch 3/3\n","  Train loss: 0.1193, acc: 0.9626\n","  Val loss:   0.1118, acc: 0.9615\n","Zapisano nowy najlepszy model!\n","Test Error: \n"," Accuracy: 96.4%, Avg loss: 0.114338 \n","\n","\n","Final test accuracy: 0.9642\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, random_split\n","from torchvision import datasets, transforms\n","\n","# Dataset + Transformacje\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","train_full = datasets.MNIST(root=\".\", train=True, transform=transform, download=True)\n","test_dataset = datasets.MNIST(root=\".\", train=False, transform=transform, download=True)\n","\n","# PodziaÅ‚ train/val\n","train_size = int(0.9 * len(train_full))\n","val_size = len(train_full) - train_size\n","train_dataset, val_dataset = random_split(train_full, [train_size, val_size])\n","\n","# DataLoadery\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n","# Model\n","\n","class SimpleMLP(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = SimpleMLP()\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# Funkcje treningowe i walidacyjne\n","\n","def train_epoch(model, loader):\n","    model.train()\n","    total_loss, correct = 0, 0\n","\n","    size = len(loader.dataset)\n","    num_batches = len(loader)\n","\n","    for x, y in loader:\n","        outputs = model(x)\n","        loss = criterion(outputs, y)\n","\n","        total_loss += loss.item()\n","        correct += (outputs.argmax(dim=1) == y).type(torch.float).sum().item()\n","\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","    avg_loss = total_loss / num_batches\n","    accuracy = correct / size\n","\n","    return avg_loss, accuracy\n","\n","def eval_epoch(model, loader):\n","    total_loss, correct = 0, 0\n","\n","    size = len(loader.dataset)\n","    num_batches = len(loader)\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            pred = model(x)\n","            total_loss += criterion(pred, y).item()\n","            correct += (pred.argmax(dim=1) == y).sum().item()\n","\n","    avg_loss = total_loss / num_batches\n","    accuracy = correct / size\n","\n","    print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_loss:>8f} \\n\")\n","\n","    return avg_loss, accuracy\n","\n","# Trening z zapisem najlepszego modelu\n","\n","EPOCHS = 3\n","best_val_loss = float('inf')\n","\n","for epoch in range(EPOCHS):\n","    train_loss, train_acc = train_epoch(model, train_loader)\n","    val_loss, val_acc = eval_epoch(model, val_loader)\n","\n","    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n","    print(f\"  Train loss: {train_loss:.4f}, acc: {train_acc:.4f}\")\n","    print(f\"  Val loss:   {val_loss:.4f}, acc: {val_acc:.4f}\")\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), \"best_model.pth\")\n","        print(\"Zapisano nowy najlepszy model!\")\n","\n","# Test koÅ„cowy: wczytanie najlepszego modelu\n","\n","model.load_state_dict(torch.load(\"best_model.pth\"))\n","\n","test_loss, test_acc = eval_epoch(model, test_loader)\n","print(\"\\nFinal test accuracy:\", test_acc)\n"]},{"cell_type":"markdown","source":["## JeÅ›li Ä‡wiczenia bÄ™dÄ… siÄ™ przedÅ‚uaÅ‚y...\n","\n","Odpowiedz na ponisze pytania pisemnie i przeÅ›lij zadanie na skos. Do zobaczenia na kolejnych zajÄ™ciach! ðŸ˜€\n","\n","1. (W tym pytaniu nie ma zÅ‚ej odpowiedzi, jeÅ›li umiesz jÄ… uzasadniÄ‡) Zbiorem danych sÄ… obrazki, na ktÃ³rych sÄ… napisane cyfry. Jakie transformacje moznaby zastosowaÄ‡ na obrazkach, za pomocÄ… ktÃ³rych bÄ™dziemy uczyli potem sieÄ‡?\n","2. Czy w sieci neuronowej dla ponizszego zbioru danych i dla tej konkretnej architektury potrzebne jest `Flatten`? Dlaczego?\n","3. W zeszÅ‚ym tygodniu omawialiÅ›my Cross Validation. Jak wyglÄ…daÅ‚oby ono w przypadku uczenia sieci neuronowej?`"],"metadata":{"id":"NUOF9ISiEdU5"}},{"cell_type":"markdown","source":["1.\n","\n","lekkie obroty, zmiany kolorÃ³w, lekkie rozciÄ…ganie, blur  \n","nie powinniÅ›my stosowaÄ‡ odbiÄ‡ lustrzanych, etc - nie chcemy tak znieksztaÅ‚ciÄ‡ obrazu, Å¼e nieprzypomina on juÅ¼ liczyb\n","\n","\n","2.\n","\n","potrzebne, bo sieÄ‡ przyjmuje jako input tensor jednowymiarowy (wektor)\n","\n","3.\n","\n","analogicznie - dzielimy zbiÃ³r treningowy na kilka grup i trenujemy sieÄ‡ biorÄ…c jednÄ… z grup jako walidacja a resztÄ™ jako trening"],"metadata":{"id":"72eokRGJElCe"}},{"cell_type":"markdown","metadata":{"id":"cXE40xISAJcx"},"source":["## â­ï¸ KMNIST â€” Kompletny Pipeline od Surowych Danych do Trenowania Sieci\n","\n","W tym zadaniu pracujesz z datasetem **KMNIST**, ale **bez uÅ¼ywania gotowego datasetu z `torchvision`**.\n","\n","Zrobisz wszystko **rÄ™cznie**:\n","\n","* pobierzesz dane z `torchvision` (zostaÅ‚o zrobione za Ciebie),\n","* zapiszesz pojedyncze obrazki jako `.jpg` (zostaÅ‚o zrobione za Ciebie),\n","* zapiszesz etykiety do plikÃ³w `.csv` (zostaÅ‚o zrobione za Ciebie),\n","* zbudujesz wÅ‚asnÄ… klasÄ™ `Dataset`,\n","* przygotujesz dataloadery,\n","* stworzysz i wytrenujesz sieÄ‡ neuronowÄ… opartÄ… o CNN.\n","\n","---\n","\n","### Przygotowanie danych\n","\n","#### Pobranie KMNIST\n","\n","ZostaÅ‚o zrobione za Ciebie\n","\n","---\n","\n","### Twoja wÅ‚asna klasa Dataset\n","\n","StwÃ³rz klasÄ™ dziedziczÄ…cÄ… po `torch.utils.data.Dataset`.\n","\n","#### Wymagania:\n","\n","#### `__init__`:\n","\n","* wczytuje odpowiedni plik CSV,\n","* przechowuje listÄ™ Å›cieÅ¼ek do obrazÃ³w i odpowiadajÄ…cych im etykiet.\n","\n","#### `__getitem__`:\n","\n","* otwiera obraz `PIL`,\n","* stosuje transformacje,\n","* zwraca:\n","\n","  ```python\n","  (tensor, label)\n","  ```\n","\n","#### `__len__`:\n","\n","* zwraca liczbÄ™ przykÅ‚adÃ³w.\n","\n","#### Transformacje\n","\n","**ObowiÄ…zkowe:**\n","\n","* `transforms.ToTensor()`\n","\n","**Opcjonalne:**\n","\n","* `transforms.Normalize((0.5,), (0.5,))`\n","\n","---\n","\n","### PodziaÅ‚ danych na train / val / test\n","\n","Dla danych treningowych:\n","\n","* **90%** â†’ train\n","* **10%** â†’ validation\n","\n","UÅ¼yj:\n","\n","```python\n","torch.utils.data.random_split\n","```\n","\n","---\n","\n","### Dataloadery\n","\n","UtwÃ³rz trzy DataLoadery:\n","\n","* **train** â€” `shuffle=True`\n","* **val** â€” `shuffle=False`\n","* **test** â€” `shuffle=False`\n","\n","#### Parametry:\n","\n","* `batch_size = 64`\n","* `num_workers = 0`\n","\n","---\n","\n","### SieÄ‡ neuronowa â€” CNN\n","\n","Zaimplementuj prosty CNN w PyTorch. JeÅ›li bÄ™dziesz miaÅ‚ problem z implementacjÄ… napisz maila do prowadzÄ…cego - pomoÅ¼emy.\n","\n","#### Zalecana architektura:\n","\n","1. `Conv2d(1, 32, 3, padding=1)`\n","2. `ReLU()`\n","3. `MaxPool2d(2)`\n","4. `Conv2d(32, 64, 3, padding=1)`\n","5. `ReLU()`\n","6. `MaxPool2d(2)`\n","7. `Flatten()`\n","8. `Linear(64*7*7, 128)`\n","9. `ReLU()`\n","10. `Linear(128, 10)`\n","\n","#### WskazÃ³wki:\n","\n","* MoÅ¼esz uÅ¼yÄ‡ `nn.Sequential` albo napisaÄ‡ `forward()` rÄ™cznie.\n","\n","#### Loss i optymalizator:\n","\n","* **CrossEntropyLoss**\n","* **Adam**, `lr=0.001`\n","\n","---\n","\n","### PÄ™tla treningowa\n","\n","Dla kaÅ¼dej epoki:\n","\n","#### W trybie `model.train()`:\n","\n","Dla kaÅ¼dego batcha:\n","\n","* oblicz logits (predykcjÄ™),\n","* policz stratÄ™,\n","* wykonaj:\n","\n","  * `optimizer.zero_grad()`\n","  * `loss.backward()`\n","  * `optimizer.step()`,\n","* policz accuracy.\n","\n","#### Po kaÅ¼dej epoce wypisz:\n","\n","* Å›redni **train loss**\n","* Å›redniÄ… **val accuracy**\n","\n","---\n","\n","### Walidacja i zapis najlepszego modelu\n","\n","Napisz funkcjÄ™ ewaluacyjnÄ…, ktÃ³ra:\n","\n","* uÅ¼ywa `model.eval()`,\n","* uÅ¼ywa `torch.no_grad()`.\n","\n","Oblicza:\n","\n","* `val_loss`\n","* `val_accuracy`\n","\n","#### Po epce:\n","\n","JeÅ›li `val_loss` jest **najlepszy dotychczas**, zapisz model:\n","\n","```python\n","torch.save(model.state_dict(), \"best_kmnist.pth\")\n","print(\"Zapisano nowy najlepszy model!\")\n","```\n","\n","---\n","\n","### Testowanie\n","\n","1. ZaÅ‚aduj najlepszy model:\n","\n","   ```python\n","   model.load_state_dict(torch.load(\"best_kmnist.pth\"))\n","   ```\n","\n","2. Uruchom ewaluacjÄ™ na zbiorze testowym.\n","\n","3. Wypisz finalne **test accuracy**.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tnwb7O34AJcz","outputId":"9e3c2570-9d50-4bb4-9554-60274f79ac5e"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18.2M/18.2M [01:15<00:00, 239kB/s] \n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29.5k/29.5k [00:00<00:00, 95.2kB/s]\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.04M/3.04M [00:06<00:00, 506kB/s] \n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.12k/5.12k [00:00<00:00, 1.29MB/s]\n"]}],"source":["# KomÃ³rka odpowiedzialna za przygotowanie danych.\n","import os\n","import csv\n","from torchvision.datasets import KMNIST\n","import torchvision.transforms as transforms\n","from PIL import Image\n","import numpy as np\n","\n","def export_kmnist(root=\"kmnist_data\"):\n","    os.makedirs(root, exist_ok=True)\n","\n","    for split in [\"train\", \"test\"]:\n","        dataset = KMNIST(\n","            root=\"./raw_kmnist\",\n","            train=(split==\"train\"),\n","            download=True\n","        )\n","\n","        img_dir = os.path.join(root, split)\n","        os.makedirs(img_dir, exist_ok=True)\n","\n","        csv_path = os.path.join(root, f\"{split}_labels.csv\")\n","\n","        with open(csv_path, \"w\", newline=\"\") as f:\n","            writer = csv.writer(f)\n","            writer.writerow([\"filename\", \"label\"])\n","\n","            for i, (img, label) in enumerate(dataset):\n","                filename = f\"img_{i:05d}.jpg\"\n","                img_path = os.path.join(img_dir, filename)\n","\n","                # zapis do jpg\n","                np_img = np.array(img)\n","                Image.fromarray(np_img).save(img_path)\n","\n","                writer.writerow([filename, label])\n","\n","export_kmnist()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfdyaC6CAJc0","outputId":"1868927a-14ff-426a-c314-d6a777f349f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1: train_loss=0.4521, train_acc=0.8384, val_loss=0.3256, val_acc=0.8792\n","Zapisano nowy najlepszy model!\n","Epoch 2: train_loss=0.2884, train_acc=0.8957, val_loss=0.2800, val_acc=0.9010\n","Zapisano nowy najlepszy model!\n","Epoch 3: train_loss=0.2457, train_acc=0.9102, val_loss=0.2644, val_acc=0.9030\n","Zapisano nowy najlepszy model!\n","Epoch 4: train_loss=0.2133, train_acc=0.9213, val_loss=0.2592, val_acc=0.9030\n","Zapisano nowy najlepszy model!\n","Epoch 5: train_loss=0.1864, train_acc=0.9312, val_loss=0.2325, val_acc=0.9142\n","Zapisano nowy najlepszy model!\n","Epoch 6: train_loss=0.1631, train_acc=0.9389, val_loss=0.2236, val_acc=0.9173\n","Zapisano nowy najlepszy model!\n","Epoch 7: train_loss=0.1413, train_acc=0.9476, val_loss=0.2368, val_acc=0.9163\n","Epoch 8: train_loss=0.1216, train_acc=0.9546, val_loss=0.2493, val_acc=0.9143\n","Epoch 9: train_loss=0.1041, train_acc=0.9613, val_loss=0.2641, val_acc=0.9120\n","Epoch 10: train_loss=0.0888, train_acc=0.9671, val_loss=0.2696, val_acc=0.9125\n","Test accuracy: 0.9134\n"]}],"source":["# Twoje rozwiÄ…zanie"]}],"metadata":{"kernelspec":{"display_name":"Python (nlp-pytorch)","language":"python","name":"nlp-pytorch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.14"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}